{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-03T09:16:21.582663535Z",
     "start_time": "2024-01-03T09:15:21.054378820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘celeba_gan’: File exists\r\n",
      "/home/nacho/anaconda3/envs/tf/lib/python3.11/site-packages/gdown/cli.py:126: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\r\n",
      "  warnings.warn(\r\n",
      "Downloading...\r\n",
      "From (uriginal): https://drive.google.com/uc?id=1O7m1010EJjLE5QxLZiM9Fpjs7Oj6e684\r\n",
      "From (redirected): https://drive.google.com/uc?id=1O7m1010EJjLE5QxLZiM9Fpjs7Oj6e684&confirm=t&uuid=639a3ddb-c6fa-4a23-a51c-1c7eec672380\r\n",
      "To: /home/nacho/Documents/dlpyhton/tf_examples/generative/image_generation/celeba_gan/data.zip\r\n",
      "100%|██████████████████████████████████████| 1.44G/1.44G [00:33<00:00, 43.2MB/s]\r\n",
      "replace celeba_gan/img_align_celeba/000001.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\r\n"
     ]
    }
   ],
   "source": [
    "# !mkdir celeba_gan\n",
    "# !gdown --id 1O7m1010EJjLE5QxLZiM9Fpjs7Oj6e684 -O celeba_gan/data.zip\n",
    "# !unzip -qq celeba_gan/data.zip -d celeba_gan"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "dataset = keras.utils.image_dataset_from_directory(\n",
    "    './celeba_gan',\n",
    "    label_mode = None,\n",
    "    image_size = (64, 64),\n",
    "    batch_size = 64,\n",
    "    smart_resize= True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8aac0b85c418782",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda x: x / 255.)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T09:16:27.142734440Z",
     "start_time": "2024-01-03T09:16:27.133726754Z"
    }
   },
   "id": "cabd3c9574d5b83a",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7f0e71c94250>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABAmklEQVR4nO2deYxt2XnVvzPdear5jfXe63bPczx1bJwocTDYwZPAIRHGCVPEJAFCAiEUwR9ISECIEAqEMUoYJWcixDFx8BR324nj2N2O23ZPr1+/qareq+FW1Z3PxB8tbTrstZp76TIJZP3+XG+/M+yzz/3qaq+7vqAsy9KEEEIIMwt/ty9ACCHE7x1UFIQQQjhUFIQQQjhUFIQQQjhUFIQQQjhUFIQQQjhUFIQQQjhUFIQQQjjieQe2l3pQZ799C0O/3rCxQRDMexn0OOwYJ/XbvKIoPA3d40mx6Jx8ayHPuMyhvsils+fD9CTBS3YyHvpjS3whK8tdqIchHj9Ip1CvVWueFgcRHDubzaC+sbEB9Uql4mlsTTzzjWehPk3xOY3MSxwnnpbn/ro3w++DmVkU4DUxA8cJIjxXRvQo8a/PzCxn12LfuneIf674nwlhMPfH7Gse+yQ+E44P+v/bMfqmIIQQwqGiIIQQwqGiIIQQwqGiIIQQwqGiIIQQwhHMG53N3Ef0wCewU86Okee+w2HR8y06HrktTsoh9K10Gp2EkwHNt5lZEuFjBMStFJT+HJZAe+UYmCjAx17utTztzot3wLHNRgPqB8eHUM+IK+l4OPK0IsXXd3R0BPVqtQp1NAPdbgeOnI4nUL/7rruh/uSTT+LjTH2XFXJYmZmdOXMG6qPBPtT3D/25LQy7jA6OB1APQuw+CmPm7vHXFlvLMTnGou64ALnPysX+9l7knWVjmTtsTOb21eibghBCCIeKghBCCIeKghBCCIeKghBCCIeKghBCCMfc7qPO8tLrPhnbET8JFs0+YuOZvsi1n4QT6luZE8X0RbOcSsNOjpA4iqrI4VGkcOxypw319bUVqN933z2eNiROi6889VWoD8a+m8jM7HCK3T3dnn8tB7cP4NiI5PmwdYVcSQnJ/qmBnKTXOuepU+tQ7/d951BSwcc4Pj7G+gDP+emN057W6eAMqtFwDPXDPnaH7ZE8n+kCr8pJvPevHMefr7J4/U5HM/x+Lnp9oyP83H7HeRY6ohBCiP+vUVEQQgjhUFEQQgjhUFEQQgjh0EbznPpJRGsw/m83JFp0LNuAZs8zDkmDHHCY5U4Tjm03cLzCUo9sTk78zcmd7dtw7IBsZFbbOEZiXOAN9QHYyK4neNMXRUi8omdQR3vELBJjPMIb4RXSkKjZwnPb7vjxH+fPn4Njb968AfWdnT7UEZ06idBYW4P66vIy1Hf3cLTG87d2PS3L8HwvGhfB+L2y0czuRzEXQgghFkJFQQghhENFQQghhENFQQghhENFQQghhGN+99EKjh0oivljFKII1yB2BbQBS+AfZxHXEDvGKzpzIfjHD1FDjdfgJNxKJTkEc1VEpBFOCK6lSHHkRJLg+6yDJiZmZg3iHCoy/1lUKji6od3ym+aYmW3tbONjA7tOEmMnUEjiH1gjnIysz2qt7mmVCnYIpdMZ1Ftkro6P+p7WqOL7Ya/w/j6JNCA9aXKwxtdPb8Cx/T6eK+aGQWuoRmI7yhyv5c2zuLFPHOPnGdf84z/37PNwbJrh92SSk4fPnjN4h2L62rOPXva3OmpSxVyK+BiDA7mPhBBCLICKghBCCIeKghBCCIeKghBCCIeKghBCCMfc7qP2MnaDLJKtwzJ0FmkEY4ZdPCfXJIMdB4w17HpYNENoEVdSThxZjIA4hMoSOIFCfD/s8toxvs9uF+cTIScYG/vSS9eh3mxiB87x0M//WSMZOgVxfYxILszps2ehfvXlK542meCMo6UlnKu0uoTzfELQwCiJ8fq5vdeHervbg3pp+IFu37rlaYMxdk3lwElmZlYSZ1cMrn19bRWO7bRwHlZ/fw/qmySfKYn8tT+b4uv+5rMvQH1U4DmflOTvaTC1EXjXTgr2WcPciNMBfp6vRt8UhBBCOFQUhBBCOFQUhBBCOFQUhBBCOFQUhBBCOOZ2HzV7flcms8U6mC3aHW0R99FJdQ3j5wSuCuZAIJxENzUSaWIF6Q4WkiynBDiNWE5STBwl9ZB0iCIZV3fccYenTSa4a9jB/gHUjw4Pod5u+S6mC5ubcOwhyTjaunkT6ilxclw472fxdNt+HpKZ2bnz2MGUkUyk0cDPLdraxrlPBwPcSS4na3xAOrVVa36eT5Vk/AwGI6gfTnF+Vgo6z62Qbo6bm9hNNB3jc46GOOPp1IbvPotCnLc0HuHn8FWSlTQlIWQ5cLZFJ9ShEbHoZ+foEK+VV6NvCkIIIRwqCkIIIRwqCkIIIRwqCkIIIRyk3YYP27A9CRbZrDZbLLqCNdlZGLBvs+j1nUTMRZbjDbFKBT/KYobH15t+lMBs+r/fhHo1zKFw5gxuhoI2v1hjm4M+3mjudHBcxP333utpt0Bsg5nZ3u5tqHe7+NgsiqPV8DdhN1bwWBahcf06jvPog3lh6+RwOIR6StZ+OiPNlEDDI9YwaTLFm77tCI/fOfavsX+AYyviAL8/Z07hhj95gqNPhmBeuh28uX08wOvwHDnnjd1dqM9ylIezmNll0WgexOtp6KVvCkIIIRwqCkIIIRwqCkIIIRwqCkIIIRwqCkIIIRxzu49OgkUa8nyrj/N6dud/N6mT2IEsw81d6nUcu1AWfnRDEuM4i0qMlwk7J2rWYmZ2/vx5TzsmzplTxMHUbreh/vQzX/U0Fs/RJg1vjg6JE+paH+oboInPjERiHJJ4jms3cXRFUfhrfDjG8RRT8jrEJLakkuC/BY/GvvusPsHrZ0IcTCFZK62W7xDibyC+oYg8z0oVn3MIIlTiALvAzp7G623vALvgKvvYIYSef1Eu9jF7Is24XofrUt8UhBBCOFQUhBBCOFQUhBBCOFQUhBBCOFQUhBBCOOZustNebr3+k/0uOH5OyvFksKkGdkN8K7OPyhw7fphziGXXTCd+dk2tgjNk0il2vSyvLkOdOYS2QZOYVguvq5WVFai/dPky1KPYn9vhEM9VGLJmR1DmWTSlP+clGRpX8XO4tYtdSWXoX0xIGsQYa3ZEGixF5P47Tb+RVkIaJoHLMzOzpS7OFkIOtiY4n5nZzhZudrS+htdEs+XneJmZ3drznUOr5PrY58TObZxxFCbYUXR123feTbAhjfKtdFcODrDb79Xom4IQQgiHioIQQgiHioIQQgiHioIQQgiHioIQQgjH3KEcARnKNsrhDvqJmY/8A5XE9sE38he7GLSbz9wqJ+GyYg6EBJuMjMS/2OgIu1uaoPNanuG8lDjBeUvjEXYyjEmeUQjm/GBvH44tU/w8gxzPS5n7uT3dJnb8jCe4G93xGLuV2h3cTS0Axymm+BgxeXC9NsmyAnM1GePrLjM8V5UEu5XIErJs6h8/qWJHWkjcbsf7fahfvLDpaRMy3xcvXoL6YHAM9V5vFeqzoW/72b+Nu+4tk455heF3oojw3FZq/pqbHuL3AcRbmZlZTI6NPhNK6Io0y1+Hg0nfFIQQQjhUFIQQQjhUFIQQQjhUFIQQQjhUFIQQQjgWaAnEHDWL7HKfjP0IO3PwsRd1Ai2SO8Iycdg5Fzk2O0YduBvMzCrEDRKFWF+kM1OaYtdLnuP773V6c59zfQU7Rw4O9qC+soSza9p1fynfIrk1Z1b9jmlmZsdDPw/KjDs8Lt1/p6fdvHYDju0PcccvI2soS33nTETWT6WCn3Gtjp1NICbqlXNm/nMuS7xO2EpeIXO7d+C7zGLijvrm889BneVkdQZ4bqdgDgPSvS0iHQ3rdfy+7Y98t5uZWRT567BG3tkROQadXKSTseHrcEDqm4IQQgiHioIQQgiHioIQQgiHioIQQgjHAhvNv3dAG7aLNrBhm76L6Oycix4bwY49HOHN0Jw0/YhBcxMzvEnONs6zDHcJWVvFm75szh+8715Pe/nyFTj24tkzUC/JBvls5G82PnyPfz4zsxdeeAHqy/U61O+86y6o72yDjWzyjAuyYRsWWK+AHcReFzcvqlbx5mlIOuHUyH1GwKxwNOjDsWwtT0DzJjOzHjAI3NrFZoIpWW/HZPyMvFanlvxN73SCN6WjCMd5DIe4wRR7J/LMvxi20TybpVBfyLtDeD1RO/qmIIQQwqGiIIQQwqGiIIQQwqGiIIQQwqGiIIQQwjG3+4jFIrBd7pNoNMNY5NiLOH7MuOtnERZ1PEXgp/dsvmvkZ/qdTgfq29s75Fr8+zx37hQce3iIG/X0ej2o0+iKPd89cmYNO5hWlpahPjo6gvrpO+7wtCeeeAKOnU6wo+RNjz4M9ZhEiLx06LuP8hl23zRC4koy7Pj6jrc85mmrXeL2CvFaqZKYi+Nj3KzmCMR8DDvYqTQY4Tk0sK7MzDZPnfaPQZrm7IJ1YmZWhPjjamcHN8457vvNbVaWsYNra3sL6hFx70Wk2ZOVvqNo0c/ChMR/DECcR6WCnU1qsiOEEOJEUFEQQgjhUFEQQgjhUFEQQgjhUFEQQgjheN3ZRyeRFfT7BXb/yGmEHElmZkGAnSa3b2MHBss+6nZ9t9IuyZY5fRq7ku65626oX335JajPRr4bZHPtAhzbaWBXxaWz+Fo+8anPeFpCms8sL5NGMLexA+XosA/1bOLfT6XEmThlgRsVve2hN0D9wx/8Xk8rSO7VaIKbtWztbEN9XMM5P3sgP6sMsePp+o3rUM8D7HjKwTWGICfIzKwe42McjadQLwP8nIeBP74+JhlHBX5ujUYT6qMRvpYo8Y/PcpIajQbUx8TZhceT/LUcn3Mefn9/SgshhPgdqCgIIYRwqCgIIYRwqCgIIYRwqCgIIYRwBOWc4UCdlR7Uy2J+99HieUjzZwgtemyWLUSvBByfu6lwng27xiz181JYt6Y4IB2fZtgN0Wwy94TvZGFZRq1WC+rtOr7GdIrdE3dfPO9pp0n3trUe1j/56U9B/dahn4m03OvCsY8++ADU+7s4J2o2xe6e8dB3H+1s34Jju6Rr2h99//ugfse5s55WJe9DmuI1MRrj6947xN3HDgb+/ewR51UY43yeg2P87F+4csXTJsQg8/xV7GzaJ5lNeYivJS3997Bdx2N7HbzGx8zxRHKYJqCbGutoWK9j99Gf/PBHoP7TP/3vPe2Nb3oLHPuZX/ss1I8O+lB/NfqmIIQQwqGiIIQQwqGiIIQQwqGiIIQQwrFAkx38M3222VqCTZ5F+z7wBj54s2gRWIwE2xRCl5IX/qaSmVkS4utmFTiu+OPLDG8SliS6odnDTXaGx3hTsQIaeRyTBjYxmatsgo+NNpTNzNo1f7nlGd7w//Tnvwj1UYkjELprZzztvntwhMQ6aeyTD/D9z0h0RXXm309zCR/7zFm/yYyZ2WN33wX1IPJXS5bj9VbN8JxEIX5uMWniklT8+4kTvGoP+rjxUjHF+lLLj3/YOfI3tl85KV4TBXmvRlO8GZzE/vjJDB9j/whHiDDDx5Scsyz9ay9A4x0zs2YbN5L61z/1b6A+GvmfwX/xr/xlOPYTn/5VqM+DvikIIYRwqCgIIYRwqCgIIYRwqCgIIYRwqCgIIYRwzO0+4i4jbClC45mzZ1HmTOY4UYoFojXY9aWk2UYNND1hY1k6x2yG3WGMwcB3N91xaROOPSbxAr1l7Hhij+cINA956eoNOPa5516AerWOYzsu3XmHp01AUx8zs6vX8P102jjqYIU4u6LMd5X06nU4dmmpB/VaBTuBSvMfdELeQdZOJQFNc8zMMuCQMTPrdsB9knNGC7gOzcxC0DgnDXHDm9UBjsrYO7wG9QSbrCCs4Q17Z5lLkY0v0AsakOeW4bn6j//hP0H9j7z3/Z72ta99HY6tk0ZK86BvCkIIIRwqCkIIIRwqCkIIIRwqCkIIIRwqCkIIIRxzu48YbBd+8YY683MSLqY4xrdOs4+AVtr8DYbMeGMfdM5F3V4siyUDTT/MzHrAUbO1tYWPQRwbMckEWiX5Py++7LtHxqQRzJQ0b6rFeF5Qg5wzGytwbHcJ6+kIu5Jqbex4aoF8oijHz+Gxb3sU6pUYu1vQ809neE6ynGQz1bCzKSMOIbjKSYOlWgW7W0ZDnIeVg3XbB42ezMxOr69CfWtvH+p7B+Sc4P1k7w/TUTMqM968KgWOtJw8nyFo0mRm9rM/9/NQf+O3vdnTPvrRn4Fjf+qnfhLq86BvCkIIIRwqCkIIIRwqCkIIIRwqCkIIIRwqCkIIIRyv233EXEaLOGoWheWRIBZ1Ar3GkXyJGKyoW4c4ntC8VEnHpzLAzpHDQ9zxKiA5RCgraUacShsb61B/7D7c2eyp334G6nHVv6f9Q+L4aeIMockUu5Ws6rthzp31u7GZmT3/wrNQ7zbwOYuiC/U1cPwzG9g5s7SC5zBLmWvMfz4V0nUvN3yMCcnDqlVJ3hJ4V2rEqVSQqK0VkvFUmP+ckxC7iarkPem1cAbVIengluUorwwOtRyMNTMjl0Jdc+jzMAywU+uQrP2nv/JVqL/ze/6Qp/3Mz/4cHPvEr30O6u979weh/mr0TUEIIYRDRUEIIYRDRUEIIYRDRUEIIYRDRUEIIYRjbvfRopkhSD+pjmknkap0EtlMLPuIOZtazQbUUee1BungtbVzE+rU2UUyhNLUdxpVgYPHjM/Vtau4E1algp1Tu8BtUYbYUTOY4O5bXeKcOQccUi9fuQLHXrn2MtQ7Vfx87t28BPUw8buJPfLmx+HYyQjn85RjfD9R7DvYxkPsVonxISwu8DpkHb+SyH/OZYbXVZV0jGs38BwOx75D6swp7Mg6uoK78YWkY1yV5EfNwPiCvA+MRfLKzMxCsJ7ZKQPyN/lBvw/1N7/5rZ72wotX4NivP4MddvOgbwpCCCEcKgpCCCEcKgpCCCEcKgpCCCEcC2w0s39hzWD8jRi+yYOPwbaCg9+FUhaE/tUUGd6EYhvqzQZuzJGAxjGHfRxbEZFN36wkk0I3oP2N5jq4RzOzS+fPQv03n3oa6vUAL6ta1d+YPczwhjLfrG9D/eGHHvK0n/3lX4Jj4whfXxLjY7cbOF7h/kce8bSoQZrShPicjQrOizgEDWWaDRy3cXh8G+oBeYMqCYm5AO8n25SulHhzt0bNCv5x0hQ/ewvx+9Np47m9fYDflWrgX+NkgiNB6EcTM6SweB9wHGZImZE1npI5D0C8T0o2vJ944vNQnwd9UxBCCOFQURBCCOFQURBCCOFQURBCCOFQURBCCOGYv8kOcRvw8b6EfgJuxt06JxFFweA/U8d1ssh9t06e4aY09ZrvsnllPG6+Y7l/n3mKnQnsnGWCYzGyKZ7DDugectf5U3DstcuXoR51sNOkYyTq4NCPekhL7AY5tYydWu9629uhfvXmdU8bEafJUh3HcHzHm74d6shJZ2Z2xz33eBpzjsTACfMKeL3VgVNrNDxa6BhkiVtR4HWI3kPq9AORGK8cHMtNEPHSHOHmOJ0uXssH39yD+rlz56D+8ta2p01B3IYZN+mx5jsBuf8SRGuwzxSm39zCMR8/9Kd+0NOyKf48+Jc/8c+gPg/6piCEEMKhoiCEEMKhoiCEEMKhoiCEEMKhoiCEEMIxv/vo/zNOwtkURbimdrs4oyYg+SrTqe+IyJhTiZTxLMXj2V32uj1Pe/CB+/HYWwdQ3/ryb0J9XMfZOoPQd0pUyHN4+AJubHOmtQT1j33ik542mmFnRjvBeUO7uztQ/6E/92GoZ7n/3NIJPnY2xTk/JXHgzGa+npKcKOaciYHDzIznSqE1R9141L1H8pbAtdRJo54maF5kZra2sgL1azvYlZSAjCcQH2Rm3KnFnGc5cZlF4AWlGW7kpNl4DPVa13fkHU3w+vnhP/dnoP793/cD5Gr+J/qmIIQQwqGiIIQQwqGiIIQQwqGiIIQQwqGiIIQQwjG3+4i5EFhuUQS2+ZnrYVEnEDvnSbBIDhO7ijTFrhfmPmJODkQcY8fGDJterEKm9r47Nz3tt37zN+DYG/0RPkiKb2gvP4Y6yn5ajrEd5NGLd0J9rdOD+uHIn/OQ5NPcf+9dUL/z4gWo10lWUgHup5hhh1BMHT/4wZW5vyYW7TjI3ln2Hi5yDPbOMvdRAsZXyPuQjrD7BjmYzPj7lpXgnBWc18UyhLKMXCRraAg+PyLiYArIJwjqUmdmVoJuiRXyCV5k/+fuSn1TEEII4VBREEII4VBREEII4VBREEII4VBREEII4ZjbfcRcOYu4dRZ1Miyis7HMabFot7cCuEFQtooZzy2KSec55p7AxyZOBmI2qJMcmb1bfnenj3z4T8Cxf+/H/gU+Z4SPHQbYUZOAKX/f42+BY9/59rfha/lHPwr1AjhNEmLX6dRwZ6/vfdf3QL0k1q4w9o+TBHhNsHCdgLyCQeCviSDEYxM0sa/BIu8yW8tszbKsoBiszxZZm906fj4hc/EQW186I/lh8BjMTUXmijWeK/zxOXMTEadWRNbQcOSvw5R0hmuQz6Z50DcFIYQQDhUFIYQQDhUFIYQQDhUFIYQQjm/ZRvPrHftaoFgItlF0UucswU/SF90gn5ENS7QZzq57ZmzjHMrW7eFNuzsunPe0g33crGQ4xLEDabUB9VmGNyG/6z4/uuIH/vD3wrF5iufqpb1dqBdgeCXBG/t/8DvfAXUWRZGS+zewf9iqteHQjESCFIbvswCbkzFp6jQlm8FsDfEGOfP/jcgMHDmIYjAzK8DGNOl3Y8vtDtQTEnPB4kzQZji79xXSwGd7h6w39rECLiVn08qigwI8M0Xmj/+Rv/P34dj3vBOv8XnQNwUhhBAOFQUhhBAOFQUhhBAOFQUhhBAOFQUhhBCOud1Hv5cogQMHNfUxM8tz9lN37FjIWAMS8BP7aoIbdozH2K3CnA8ZuMaENNMpp7iON2r4Ue7296F+4ZE/5mmf+62v4nPWm1Bnc37XKd/ZZGb2l/78X/K0aoTvs9PqQj0e4zk8ve67Rx4EDiszs7c++DDUQ2QnMrPR8QHUGyBeYjTDx4hIQ5W4ypom+Wsoon4drIcRXp+1Bj7nZOI3U6rV8bo6HmDXVFziaxmBSIeIrNlegZsanV/Ba+LyjatQR+QkKmRnvw/1Wgu7ySbDAT4+iJ0ImDUwxnqFzPkIfK58+x94Kxz7x/8Ejqx5/plv4mt5FfqmIIQQwqGiIIQQwqGiIIQQwqGiIIQQwqGiIIQQwjG3+4jl+ZzEeDqWNM8IgJMjI3k7i+a8sEuJI3+qWAMSljmzSFOe6WwKx1aqOMuo3WtBvRbiefm1z37G077x9Rfg2DjDk9IMsEvkjjWcI/Pk55/wtLPnTsOxP/+LH4P6UYSf54ff6bswPvTuPwLHjsbYOdKs4aYvzPQzOfaPU42wK2dKDCiVFnZ2TYEraUSysywgjXqI42lG1lYMmt6Mx3j9ZCT8Z8Z08C5npPlMTN77C6fW8finsGMQ9bBBzbLMzIoCr3HmJKxWsLNrMgZzSz/eyFxNJlCv1/xzfuC9eI3PWF7XHOibghBCCIeKghBCCIeKghBCCIeKghBCCIeKghBCCMf/k9lHyDnEOkHFpFsTG8+cQ+iczH3E3FQT4iqY93xmZsQIZDPQZcrMbGMJu5UaIOfn0irOlnnfez8A9WSG5/DqdZxFc+3lFz3t5v4WHPu1l69A/f0f/MNQf+MDb/C0Vg1PVhziZzwpsCtnQvKzoty3JR0Pj+DYveEx1G/2ca7SEDiHDkZDOLaBDTV2RLrUVUlHulbDd5Ntnj8Dx+aGnXRj1ALPzKbABVgSZ2BE7Dprbbw+1zpYvzHq+9cxxs8yRFYlM4sC/B6yTLU48Y+T0+6PJPsoxM8nAXqLuBH7xDU1D/qmIIQQwqGiIIQQwqGiIIQQwqGiIIQQwvG6N5rZxiyKl2AbsFRf4JzsGCzmgo2n0RVgwzolsQM8QgOfc5H7mWX4nEGIf3a/efoU1O89u+Fp97z7PXDs0RBvkMdVfI33P3wP1AOQF3Hz2g049oFOD+qPreD7ObO85GnTEd7cDWsNqEdVHNsxPMIbvDe3b3na1Wt443x3Dzc7Ojz2G9uYmY3AhmhSwTEc6xurUF9dW4Z6PcYbmbOJf59PP/01OPb4sA/1O++7F+oGYmIi1mQmwaaJyRQbATbP4DXx9Ja/iR+Tew/ZhnLGPj+gbAF494sM3yfbxGbxFwFo4NNu4HibIsNzNQ/6piCEEMKhoiCEEMKhoiCEEMKhoiCEEMKhoiCEEMIxt/uIuYwWdRQtcuyS/Ax8wX4/kJTEQlSr2OGBYjEWbeCzSJMdNicx0Zvkp/E1ojcabU/74le+Csd+8wqOrTg42Ib6HRfvhPq7vvN7PC2f4qiMv/an/izUixl2Qh0f+M6ZWoxdRpWErDfibslJZECZ++MrFXzss+exQ+YiucbJxJ+XOy/4UR5mZp2NHtTjmDjypngOAxDdMD0+hGOf++Y3oH7z6k2or57zHVINEkETMccP+RM2qeLjNGq+m2x8iBss5SU5OPmwqSR4fAPETqB3zcxsv4/ndjrFn01h5L/L7W4Hjp2MsdttHvRNQQghhENFQQghhENFQQghhENFQQghhENFQQghhGNu99GiTpsTcR+x3CJsqFno2MwJxO4zBjv/JdDMeH4SY5GcqKQkjUlyrK/1cC7ON559wdNeuIndRJ1zF6C+0cQNPr76nN9Mx8xsFvjOrjc+cB8cexBhB0alRrK2Bv6cNzt4TjpLOOMoIA1iGqQpzWbbd5Wsxti9tkWcJl95Frt4vvLc85524V48V9Ucz9WlzfNQv+vCRajXQKOZuMDHvueOO6C+coSdTbeOb3taQpx+hWEXWFLD76xFpEEO+GhKWO7TlLyz7GOswJ97BXA1TojjqZjhuWWNwbLCd6RdJg2t/u7f+OtQnwd9UxBCCOFQURBCCOFQURBCCOFQURBCCOFQURBCCOGY230UhDijxgLiBgEuGepIInII3BBmZgEwCkTEgTDL8HVHMa6HLG+pAI6iHGTFmPHuTjE552TiuxCoeYvcZ2H4Ps9s+B3WzMyW6r5zqD/A7hsz7PrYqOFub9kqPuebHnuLp33/D3w/HPupj/8C1BttnBU02vW7bJHYJ6sm+LrJ47RKFXe3msz8NZ5W8EmfeQHnSlXrOLvmaN/PcrpnE7uPfvmJX4f6k199Eupne/ha3vrg3f45z63BsZ06nsOQ5Er1Wv4css6FeYCPbRFeh1GK36sq6EYYBvicRbnY51sKstDMzJoN/xqrFbxma03svpqwfK+xrw+OsVPrR/7Bj0H9L//Vvwn1V6NvCkIIIRwqCkIIIRwqCkIIIRwqCkIIIRwqCkIIIRxzu48WzTgqQScjlkO0KOhaAuISYBQgR+QVHefloGtfJN/ptY4dgZAW2nktxg6Mu+/2nSNmZufP4I5f3Ut+Lk6nSzpEkU5Q/at+Po+Z2VseeQDqy03fDfKlL/waHJtPjqF++iK+z/2Zbx1KEry8KyRzJ6jg8SnpyNZoNj2tjPFc1ev4nI1uD+prq35m1S//11+AY7/vB38Y6ndcugj1n/yJfwr1X/3V/+Zp63/0/XBspdKFegO4jMzMEpDns0fmla3xIsDvTxM8BzOzCDjy6mRNFCRQbUw6NLLPjxFwElaJI2tjHeeSpRl2SI2vXve0KVj3Zma1Gs4lmwd9UxBCCOFQURBCCOFQURBCCOFQURBCCOF43U12+Ebz69+YXehaSPOZnPwcvSjw5g/a9DUzQ/u+LIaD7aeza0Eb52xsu443gx964EGoN0kcQTP25+uRN5yFY/cGY3wt9+ImLkGCN7nqvSVPm5DNxjc88hDUiymOAEBNk1izEtQwycxsAmIEzPiziMDx1zo4tuLbvu0xqF+5egPq7/zud4Dz4Wd5vOVvQJqZffqZp6D+xodwXMabHvAb55y/tAnHrq/6z9LMLCJrvw+aDPUD3HioJO9gQXJIVlZXoN6qIEMKidAY4nVoBV4rI5KKUYLMnuMhbrJzOsDXvdTDa6i1679X4ymew+O+H/syL/qmIIQQwqGiIIQQwqGiIIQQwqGiIIQQwqGiIIQQwjF/k50FnUNo/Em5j9BxZuTn6BFxmhhpSsPiJSoV392CHC9mZsOh3yDFjN9/Bhr4sM5DDRLRsLJEYgca2G1RB/dfSfDfCM1aDeoFe54hnpcKaD60voR/6k+MXXbjYA//AzoGiWbJ4XybTWnsAn5NAnA/1Tqeq3NnTuNrIettNPavpQPcW2ZmzQppAjQdQT0h7p4GiCGpVkljGyNuxBl+r6rIHcYiJ0LysZTi55YT52Gz5p+zXsELK2HuxQDff3+MryUL/Lkdkedw7foVqD/y0MNQX+n67/iIuKYmxDE3D/qmIIQQwqGiIIQQwqGiIIQQwqGiIIQQwqGiIIQQwjG3++gkOKkmO3nuOwXYsZn7iDXJYA4h1MhjMMCZJqzpx2iEXQgIlqsE4lzMzKxOHBsss8qA0yiuNODQGnHURDXshEKZQGZmjYZ//DHJMrpFXEYz4m6pAYcUdXsRZwZzk2VkbaGjpClukNJu4zWxef4M1OFjI/dTr+DnkKdYL8maQNlCIckIYz2t2HtYouOQpcma6cxI9lGFOKQevt/PeHrDpQtw7HiA383S8OfHr37m81B/6iU/yypq4ueQEsfkra2bUF8DGU9bN3fg2GjBpmOvRt8UhBBCOFQUhBBCOFQUhBBCOFQUhBBCOFQUhBBCOP6fdB8hRw2JLqH5N1GEM4GY6wfB3C3r6+tQf/nKlbmPza6jQRw/eY5dL5MR7poWLPvdncIYHzupYudMXMNzGBBbycGB3w1qOMHXl+d4rYSk+1gJ3GSTCXY2DUknrARkGZm9RtfB2F9b6YxlcOFXrdvGnfQKsKBHQ+yQSWd4DhPiAmPdBUPwTsxmeF2lJIdoNsbXmGV4XhAjsmZZNlVK3GRve/xxTzt/Cnc7O9rbxcee4Ptcfe+7oL790//Z025O8b1XSPbTzZu4k97a2oanraz04Njru7gj2zzom4IQQgiHioIQQgiHioIQQgiHioIQQgjH3BvNLC6CbR6jzTm2MUs38sj4IPZ/1p6R2IpqgK87ikizDbI5l6f+8WMyJ+kMb4h1mjhGAsVftOpk07eOz1k1/BzapFlPBJ5bEOOxMXsOKW4mxJqeVBLQeCnGc7Kzh2MujvpYXwIxEjWykVeS60tJhEZA5jAs/L+p2IZyLcLPEzdYMhgB0SYb/mGIjw32wc3MLMjx+pyOjjxtnLJNX3zdaXYM9Vnqn5OtkwnZ3J3OsN6u43lpg0eRks3q9VM4buT555+H+rnNs1A/vbbsacc3b+Nzrq9BfXcfr/GbO9ueVq/jBkvVBL+b86BvCkIIIRwqCkIIIRwqCkIIIRwqCkIIIRwqCkIIIRxzu4+GpAkFa3ARBKjekIYdxN3Cmp4g50NAHEzUZUScQxlpfBGB2IkqiUWoV3AUw5DcJ4riCEjTHCP6eIrjCFiDmErVd6yQyzPcTsasQpw2RualBCe4fPUaHMviInLS9KUOHChxFTcHYn2HWNOXnDR3yTI/RqPVwbEVjJi53UB0Axsb17CDKyFxFuND7MBBBBlpyENcPFPgMjIzQ8twBhx9ZrwJUgzWrJnZ2jqOrqiDd3x4RNxRGV78E+Ia+5UvfBHq230/QuWhhx6CY+MKcUYS19zuvu8OO01iO4KdW1CfB31TEEII4VBREEII4VBREEII4VBREEII4VBREEII4ZjbfXTh4ibUU5KB0j/yG6os2mSH5cKUQE8SvJPfbuFskMGRv5NvZhYF+Bo7Ld/dwlwph+Dezfj9zEBDmXyIM2fGxB01Y3NLLEXT1HfOBMQNEdfwHBYlvp+gwOfcA012jg5xMxDmvmrU61BfWvYzZ2o17D4iJjiLyFyNSXObDDz/PZLZxBx2rHFMp+M3QWqRtRzU8X2SV8KGR8RmVfqun5Ks8ZI038lIntEsA2ucZEoVpMFUSJyORYhv9ODAX1tJE89ho9WF+n//pV+B+md//Teh3mr3PK3bxcd+/sXnoL556QLUDw6f9TTs8jSL2cOfA31TEEII4VBREEII4VBREEII4VBREEII4VBREEII4ZjbfcR20C9fvgx15LZgDgyU82LG3Uoo0qVFXAUZ6YIWkqCbahXnFoXAlbS0jOfk+s0dqBNTDjTD5CWZqxLX8b1+H+qjFZzF0yuQiwfPSTbznUpm/C+KdILnPAZZSdMxPnarjee2VsXuowrIPlo/dRqOvXntOtQzEooUkvybStV/RkPQRc+Mdxfsk+eG1j5zr62eI13dCubeY7lSvs4cZiVx6RUp0cF6ZtlHFeKymhFX0ijHc9tbWve0rz2HO6l98j/+HNRf3iYZQhH+nBgM/Y5nV65cgWPZ59t1sj4nE/9dOSTuvZhkvs2DvikIIYRwqCgIIYRwqCgIIYRwqCgIIYRwqCgIIYRwzO0+unr1KtSZq4I5jRYZy44Qg45sJbmOGcloqVbwrbeavovFzCwsfWfGZITziVCXNjOz8QS7PkKQ3RKRrnP9ge9uMDO7SVwSswtnoZ4CB0qe4bnKA3wtZY7vMyVusmnqH7/bxu6oI+DiMDMb7t6Geru35GnHx34XLDOzKXluJXGxsDWOHGm9Xg+OXVryr8/MrE6ynJBjhblV4lu7UK/EePxsih1fM5CrlYbkvSJ6RuYQGaeIwc4GxJGWJvhv2I/+4n+Beq/u52Ft72Bn4BpxqiU1vIYmZG3NQJYVc5ilOX7fAtIxrw3elSl5lqxr5Tzom4IQQgiHioIQQgiHioIQQgiHioIQQgjH3BvNBdk8DMl28Gzqb1qFZAM2ClltwuPj2L9s1r4nIOdkcRbrKz2oDwb+xtJwSDYyZzgaYJH7iRJ8fVmKj/2FL/0W1L/zkXuh3hr6m9txjBtzJAVeJvmQbEzTOAJ/TbR6ONKg1fObzJgZbRr07HNf9zS26Vsjm7unNs5APSSLa6kHNslJk5nRCK8VI5vYS0v+/R/09+HYnMRW9NqkORIzFKCx5N6zDH8eGGl4k5l/jWVEmjolOLbjJ3/630F9lWwSv7TlmxIaNfzs+we46VZINvfzGZ7zAjz/ffDZYWZGXhNbIus2BA11UtAsy8ys3saGmXnQNwUhhBAOFQUhhBAOFQUhhBAOFQUhhBAOFQUhhBCO+d1HxPXCfnpfTfxDL9pkJwU/uzczC4FbKSHOmQg0djEzM9KApEtcL8Oh3zxlSkxGYYjPiebEDBtQphPcrCWdEbdXgRvb3CLOh5VOzdPGAxz/kA7xsaOA3E+M/9aYFv5zruf4uVXBWDOzWoh/vv+Oi3d5Wkl+6h8SZ9dKbxXq+QxfywREqExDvGbZe8IiJ5oN//kkMY7K2L6Om7KUKV7LLAIBxXlMx3iRFxl2TeVEnwG3UkZsXVe3cRRFrYnv/+pVHPFSTXyn0WyC7ydp4DnpEAfX1m18zil4zhFpjNWKscsqIO8VsliWJV6bObNjzoG+KQghhHCoKAghhHCoKAghhHCoKAghhHCoKAghhHDM7T5i7gnkBGLjWbMS5j5ix0bjK8TZU5JUpErVd3eYmV0nTg50iRnqHGJmEWmSkZNrQVPLmxThY88yfOz9Pm5Wk5/182ICkjljJFtnb3aMx09J3hRo1nPcxy6rEY7nsSpxk42aDU9rkhyr5ZU1qEe9LtTzY3yN030wtxFrSgNlyxLsvkI9bPIBnpTVVeyaur51E+qtFnbUoPcty4n7iPbQYp8H/n/IiEWmQtxhN25uQT0gjrQMuX6IsyeY4ec2IM2eSvZ5AxyTFZLxFJAstCZp9IWa9YQsr0xNdoQQQpwEKgpCCCEcKgpCCCEcKgpCCCEcKgpCCCEcc7uPmBuGOYqYcwjBnE3s2EkFuxPgWLILn1PnEO7MdHR46GnsHiPiNiiJ24K5mBAsDyoC7g4zs+2DPtSPxv5xNtd9B4+Z2YUN7G457O9B/epLN6D+5Oee8LTu8gYcu3zqLNRXl/G1hMcgWyfD7qi1jXNQ79/YhfpLl1+E+mTgO1PGM5wfNYqww+5ojDt+FSiH6gi7oC7cexHqS+vLUJ+BzCYzsxC842RZsSaCFrNcpYmfnzWe4ut44vOfh/p0SjK4Kvg9TIALkN1PRrK2RlP8PNn9o86AMXHMRaCTmpnZaISfcw4+D1ugQ5+ZWR7gz6B50DcFIYQQDhUFIYQQDhUFIYQQDhUFIYQQjte90cxAm8e00cgMb54m5KfkKOaiJD/3Jqe0SgVHOkwmuOlJHPvXUuJ98NeI88D3ie6nIBee5+TYBR7/tWcvQ/3bH3vU0/okzuH8On72LRIVsrl+Cuq3LtzpadMYH+OR7/wuqFdIBMDohZc9bbd/AMf+9osvQb1exyaDagdv5lXBtVw6hTfOo5I0dwnxuv3Ex3/Z0x54y1vh2I0LOLZjb/821CvEqIE2oAsS/1Cp4vdnNMXjU2CyKMnfpBPSvWpMrqXbwPfTAOszMnzswZFvJDEzq5HolxFpXtWu+2aNCtloRtdnZnbx4kWof/mppzytk6zAsQl5r+ZB3xSEEEI4VBSEEEI4VBSEEEI4VBSEEEI4VBSEEEI45nYfLdoIBzmN2FjmMmLxD+in9CzOIkmwc4Y5MNIU/5QeO4pIwxsSI8CcQwh272GI7yeM8f1cu7kN9cnMfz6TDD/j7Z0dqFfWsDMjTYhLZNV3SkwzfN3lBLupzjxwF9Snm350xd0tHNtRb5DrHuGGKgGJFjm65bt7KsQh86VPfgbqOYk0ePjeBzxt484LcGwU47USLPBumpnNwH2y2AoW5TI+xNEiyNW3Q9ZVQNw6nS52gSWkKU8DOAxTEO9iZrbUwsc+JK6kNnEO1YH7KCSZGOwzlc1tG9w/i+24desW/oc50DcFIYQQDhUFIYQQDhUFIYQQDhUFIYQQDhUFIYQQjrndRyukGcqQOG0+8alPe9rHP+bnuZiZ/aN/8PegPhlgJ0Oa+rv24zHOLCoKfItHhl0iAXFmlKAhxpRktIyIw4E5noLAP2fByjXpnTGd4WspgRvCzOzTX/ySp63/oXfAsbURfg7VfXyfLC+nc8bPRPrml78Ox7aefgrqt5/+baiHVX9iogp+9kGMJxe5O8zMGg3sNBnt+02Gxoc4b2k2xM10zl3ahPraedBMKMDzfTjoQ71Wx+ttOsFrpRL7bh3m7JmOsUtvSsYfpf6a+I0vPQXH3t7H6y1P8XWvbPSgXov9c/ZqLTh2DBommZk1azgPqySurHrTf9+ODnAzqhr5PGiS5zYBTrWojrPAZuTzYB70TUEIIYRDRUEIIYRDRUEIIYRDRUEIIYRDRUEIIYRjbvfRQb8P9c8DF4uZWb3tOzne/8EPwLHv+p7vgPq/+uc/DvX7H3jY0/7xj/5DODZNsTsqCvGtz1LsYkK5RRnJCmJkwDXFKElOEsutiSKSw0Su8be/8aynfddb/Hk1M+vWl6C+nGBnxv5RH+oFaFV34Q3YfdO/jrNbTnWXob4U+i6MmGT/sKfQIuP7t3EHs/6+f41N0gXsrvtxZlPcxu6wEizP2QyvzSrJCiqAY87MbFpgF1Oz7TtzJlPieCI5US9euQL1y+B5EpOajSbY2dQGnylmZrMJvpaNUz1Py5gzsIbzsELSoTGsY0fa5Zde9LT1Zfz+TCc492p3l6z9M6c97XiKV3NBOjHOg74pCCGEcKgoCCGEcKgoCCGEcKgoCCGEcKgoCCGEcMyffbS+DvUa2bV/8xsf87QwxDvi3/GOx6E+Iy6ERx/zHR7Ly9iVsrV1E+oh6W5k2JxgEXCmFAV2NsUkW4d1XgtAZybWYS2uki51sDOckZ5PZlnm3+gv/NLH4diPfOj9UE+M5EQR50Ol4ufFxE18P+fuxq6kgmTupMCZkxfYmVGpYofQ7j7uBNYiHdzuvM93FJUV4vgpieeJ5DPNQOe9OMRrthbhd3AwHUA9jnBuzwTk5Rwc48ym24d9qJc5zty5fv26p41JPk9K3pOUdCM8ewp/No1AVtAb7sQusJ0d7DBrtbtQf/qZr0F9BvKZMnI/zVYb6uz+kRMsTfG7lpJugfOgbwpCCCEcKgpCCCEcKgpCCCEcKgpCCCEcc280v+8DHyD/QuIYMn/jb0Z+Xv8rn/gE1GOyGfzrn/8NT+u0cbOJTgdv5szIT8xZjISBTdUwwmOrFRz/cHiIm4eUpb8dHJF7r5OGL8fH+Nj1Kt6ERPdz+doWHPnZLz4F9Xe+6UGot2r4GuPI3+BtkrElWSu1Jn7O9cS/zzjGG6pGNvFXSeOUWgM/zwzEdrBjV8mOf0426wuwCZuQOIvJlDS8mWAjxIhsQg4n/ju7s7sPx26T6I8qMBOY4YiKbPsQjjUSQRMGeBLTKY7/2Fhf87S9Q7xxPiKb2NNjfI17ZKO9GvtrvNrARoWcRNDsH+Bz5mBe9vbxdWijWQghxImgoiCEEMKhoiCEEMKhoiCEEMKhoiCEEMIxt/voIz/0p6H+hV9/EurTif8T+5A0MTHitIkT4rQ56HvagLgE1oEDwcwsJC6jhDhQZjPfyVGlzh7syGLRFehSmPsom2JHSb2CoxuSmMwtOH5I7udjn3oC6qdWcPOQ8xt4zutV3zm01MHOHthlxswCModp1X9uAZmTmLh4KnV8LQmJcolApEFKnEApidzIiI6eW47cTmZ2BOIczMxmzGU0GkN9a9tv7rJ9Czd8WVlZgfrhGL+HL16+7GmF4febpDzQpknZFN/PLeCQmuR4vmsdv8GQmdmLzzyPL4b8PZ2CuBnkLjTjnzVG7nPvwP9MHROHWQbW5rzom4IQQgiHioIQQgiHioIQQgiHioIQQgiHioIQQgjH3O6j4yFu2PHoo49C/Uf+9t/ytH/zk/8Wjh1MsEtiSmwI586d87Tr116GY9kOf5Bj99F4MiTH8adqSpwmjQbO5xlF2CWBmu9EEcnQAS4bM7OSNNlp1LADZ5b6Low8wH8jVOp+bo2Z2X/6RdyU5898//dBfanhu2S6JFeolrAMKuymClKQH0Xup05cbe0EO1CmI5ytEwAnS0gaDAXEOVQSN8zEfD0j660/wLlXkzG+7m3gMjIz2wWNZpaXsMtoqYmbzxwc7eJj3z7wtGGCc8kapPnM0hLW+7duQH1144ynBcSN12jjY5ekYVaY4+MUme8GSskzLkt87CLDayUD7+x0htdERFx686BvCkIIIRwqCkIIIRwqCkIIIRwqCkIIIRwqCkIIIRxByVuN/Q6++70fhPqP//iPk//hH5Z1GsqojnM9rr74NU/7oR/8CBy7vrIK9VqC3QMj4uSoRn79jEhGCctEunr9KtTD2Hc2RSG+PtbVrUk6klXr2GmDcnFYJs7yGnagPPv1F6B+79llqH/ove/xtIvnLsCxZ9qkg1eE10TY9B1S7RZ2yKAuYGZmcYyf2/ERXhOoEdgsxW6QWYqvG2VqmZkVwE22v+87eMzMDo9wN7HDQ9I1bBe7jzY3Nz2tTvKgZil2Nr1w4zrU/8VH/e6KByl+fxo1vPaJIc9K4iZbX/YzuNIxnqugxFlBB/vYTWWsqx/4O7tB3s1aHXdkm2T4I3n71p6n5cTtNsvx/YyP8HN7NfqmIIQQwqGiIIQQwqGiIIQQwqGiIIQQwqGiIIQQwjF39tGTn/0k1N/4yINQb4Eske9+5zvh2Lc9/jjUez3sEvnRf/j3Pa1BXBIlyZxJEuw0qZJuXc2qr89IFk2IbClmVq3gcxbAqVUj3b7iCLsekFvFzKxNMl329vc9bTLB7qODA+x6qUXY+bDSxs/iC5/7nKctvbsHxzZDkovTJR3mIl+PiEOk08Ud45IqdoPMZnhuJyAna0AywpjLaEo66R0f+y6ZnZ0dOHZ313elmJkVpKvbXXe9AeoNkEPF3p8pmRO2DifgPvMCf/w069itw+aQZSXN0HomeWrpDLtyqjW8lkdTnNdmILOKfBxYQYyfLFMtBxlKGbmfEnymzIu+KQghhHCoKAghhHCoKAghhHCoKAghhHDMvdFcpH6DFDOzWoQ3Yizzx3/iYz8Hh378F34G6mWAN0sqIKKCxVPEZMPlYILvp9vCm1zTib/5UycREgHZWYpBnIWZ2RREILCxLCqENRM6PsbzgkhB9IWZmY3wXHVII5zvevyNUP/600972uc++yk49j1/8F1Q79XxRnMw8q89CfGG3c4NHPPA5pAxAfPS38ObvsMhbt60tbUFdbRhy57lPXfdBXX2PJe62MCBUlumU9JgiGxiF+SceerfT62OzRQdEkNy7fo1qEcVfI0FuPZLm2fh2J1tfIwcNLYxM0tJvEQTbNbXavhzYpriKAoUQWNmhhKJWEqRNpqFEEKcCCoKQgghHCoKQgghHCoKQgghHCoKQgghHHO7j5okdsGM/Ax+hN0WC0F21mczf3eexUJUE3yLKXEfxRH+yXwGjAKLOn6YGwQ15UE/aTfjjWC6XdxQZkCcQ4s4GZgb4lQDx0LEpDnSh977bk/79x/9r3Dsf/v4x8gx3gt1y33H1ww4xszMajW8Ntmcs2ZPh0d9T5uQdfXlL38Z6o/TiJeep7G4kSDAf9t1O3gtVyp43eagMUsMmkuZmRGZNsxCDXJKct19cp+VEL/LZYFdPGXhr9ucPMsMfKaYmYUxuf8Sz+EMOIrYex+RyBr2uYeHkrEkWmMe9E1BCCGEQ0VBCCGEQ0VBCCGEQ0VBCCGEQ0VBCCGEY2730RQ4E8x4zk+IglToljjeQY9DP+PIzKzMfQdBQhqqxPgQFhO3EsouMTMbAmdKq9WCY5n7aJFGODSHp8Q3NBjg5i5V0nzo5tZNfHwAe8Z10tykQTJtUFOev/YXfhiO/dmfx66kf/Jj/xjqd9550dPOnzsDx7ZIvtVgyFxj2MV0+rR//Le//e1w7Ob5c1BnGTVj4BpLiBOmUsHPuFrFayidkeZQwCKEXENmZgX5PCjJGq9V/PyfgjS0GgJXl5lZTN6JEVn7yy3fHZeRRj31Js4n6g9IrhJ5D1PgbmKutoD8TZ6R8dRphI7NOvvMgb4pCCGEcKgoCCGEcKgoCCGEcKgoCCGEcKgoCCGEcMztPgpJJ7CSdCDKwU75ovvhQYR3+Js13z3SIo6XMsduCNLUjV5jBTgfxqMxHLu2tgb1/uEh1FOQu8LmdWP9NNT39/eJjjuBISdUhgKezKxOsnI6Hdwhq5KQZ1H6rooixe6OD30QZxy957uxu+fGtt9NLQcuNTOzhNzPmy89CvUe6VSGVksFuGzMzGbE9cJcY2w8Iknwqq2S+6RZQeD5pBnO7YmJrY/9ldkCOVmH5N0siMsmZXMSYxfTqVPr/jn7OFeJzXdBOswFAb7/CLgu2XuVkOwj9hm0iKOIfe7Ng74pCCGEcKgoCCGEcKgoCCGEcKgoCCGEcMy90VyQoQHZsY3BZlEckkgMsilSJzEXG6ChDIuFmJKmJw0SczEjzYGiyN/MOjrAsQiTKd48bSS4KU028jfzml08tpji+4nIc5iQRjMZaAbSJnPSruPN00fO4piPVpNsoCX+HEYx3sgLDT+HVgsf+8I5fwM+Iw2gYnI/NRJ/UQQsQsVfn+MZiUUg8Q8FeW45unbW8IZsNJcBaXiT4ONMp8DwAEeaZTl57w3PVa/mX+NogDexB2y+yXUnJMqm0vA/J+IxifggG821Gj74lJhMaqBhFnv2p09j08jx+GWohxM0X/gZV4gxaB70TUEIIYRDRUEIIYRDRUEIIYRDRUEIIYRDRUEIIYRj/pgL2t8B/0MA3BNZinfKu6RZzeryEtTrNd+dwH5K3u32oD4Z4XgB9DN1M7NJ6u/8b+/vwrE14m6JIzzds8yfq5JYKkLgbjAzmxzhCI1ahbjGQHxBMMHOmUcfvg/q68srUE+IayxCsSXkp/sRcdqkrIlL1Xc2TXLsbjESXcD+QiKXYkHpX0tEHHZ5xhqt4PcnATESMXGUNJvYNcXeCaazZjAIFrnQ6eJ3OQHOoYh08KmQZkLDIXakrW2ehfpyz3cfjY9xzEUGnHFmZkackZUEz2EI5iUka+LgYLHIDTTn7Dks8iz/V/RNQQghhENFQQghhENFQQghhENFQQghhENFQQghhCMoS9LRQgghxO879E1BCCGEQ0VBCCGEQ0VBCCGEQ0VBCCGEQ0VBCCGEQ0VBCCGEQ0VBCCGEQ0VBCCGEQ0VBCCGE438AFkTfGIHpuJEAAAAASUVORK5CYII="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sample = next(iter(dataset))\n",
    "plt.axis('off')\n",
    "plt.imshow((sample.numpy()*255).astype('int32')[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T09:16:27.497939584Z",
     "start_time": "2024-01-03T09:16:27.144530722Z"
    }
   },
   "id": "3fc5c148c072afd",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "discriminator = keras.Sequential([\n",
    "    keras.Input(shape = (64, 64, 3)),\n",
    "    layers.Conv2D(64, 4, 2, padding='same'),\n",
    "    layers.LeakyReLU(0.2),\n",
    "    layers.Conv2D(128, 4, 2, padding='same'),\n",
    "    layers.LeakyReLU(0.2),\n",
    "    layers.Conv2D(128, 4, 2, padding='same'),\n",
    "    layers.LeakyReLU(0.2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "], name = 'discriminator')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T09:16:27.541913698Z",
     "start_time": "2024-01-03T09:16:27.491872387Z"
    }
   },
   "id": "2c3eb649dcd03c42",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 64)        3136      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 128)       131200    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 128)         262272    \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 8193      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 404801 (1.54 MB)\n",
      "Trainable params: 404801 (1.54 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T09:16:27.587534497Z",
     "start_time": "2024-01-03T09:16:27.542376244Z"
    }
   },
   "id": "db3ce845318d1ccf",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "latent_dim = 256\n",
    "\n",
    "generator = keras.Sequential([\n",
    "    keras.Input(shape = (latent_dim,)),\n",
    "    layers.Dense(8 * 8 * 128, activation = 'relu'),\n",
    "    layers.Reshape((8, 8, 128)),\n",
    "    layers.Conv2DTranspose(128, 4, 2, padding='same'),\n",
    "    layers.ReLU(),\n",
    "    layers.Conv2DTranspose(256, 4, 2, padding='same'),\n",
    "    layers.ReLU(),\n",
    "    layers.Conv2DTranspose(512, 4, 2, padding='same'),\n",
    "    layers.ReLU(),\n",
    "    layers.Conv2D(3, 5, padding='same', activation = 'sigmoid'),\n",
    "], name = 'generator')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T09:16:27.620264598Z",
     "start_time": "2024-01-03T09:16:27.586200721Z"
    }
   },
   "id": "954124a1bd2f50ab",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 8192)              2105344   \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTr  (None, 16, 16, 128)       262272    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2D  (None, 32, 32, 256)       524544    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2D  (None, 64, 64, 512)       2097664   \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 64, 64, 512)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 64, 64, 3)         38403     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5028227 (19.18 MB)\n",
      "Trainable params: 5028227 (19.18 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T09:16:27.622377996Z",
     "start_time": "2024-01-03T09:16:27.620247018Z"
    }
   },
   "id": "51ae7f2fb0426a72",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.d_loss_metric = tf.keras.metrics.Mean(name='d_loss')\n",
    "        self.g_loss_metric = tf.keras.metrics.Mean(name='g_loss')\n",
    "        \n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, real_images):\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vector = tf.random.normal([batch_size, latent_dim])\n",
    "        generated_images = self.generator(random_latent_vector)\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "        labels = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0)\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
    "        \n",
    "        random_latent_vector = tf.random.normal([batch_size, latent_dim])\n",
    "        \n",
    "        misleading_labels = tf.zeros([batch_size, 1])\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vector))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "            \n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "        \n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        \n",
    "        return {\n",
    "            \"d_loss\": self.d_loss_metric.result(),\n",
    "            \"g_loss\": self.g_loss_metric.result()\n",
    "        }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T09:16:27.623816841Z",
     "start_time": "2024-01-03T09:16:27.620959471Z"
    }
   },
   "id": "2f4c5a4bdebe83",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class GANMonitor(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=256):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vector = tf.random.normal([self.num_img, self.latent_dim])\n",
    "        generated_images = self.model.generator(random_latent_vector)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        \n",
    "        for i in range(self.num_img):\n",
    "            img = keras.utils.array_to_img(generated_images[i])\n",
    "            img.save(f'generated_image_{epoch:03d}_{i}.png')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T09:16:27.624342495Z",
     "start_time": "2024-01-03T09:16:27.621088670Z"
    }
   },
   "id": "61706880d2c4bf2",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "\n",
    "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "\n",
    "gan.compile(d_optimizer=keras.optimizers.Adam(learning_rate=0.00001), \n",
    "            g_optimizer=keras.optimizers.Adam(learning_rate=0.0001), \n",
    "            loss_fn=keras.losses.BinaryCrossentropy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T09:16:27.633374603Z",
     "start_time": "2024-01-03T09:16:27.621207128Z"
    }
   },
   "id": "aadabb4fd24ad402",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 10:16:28.858040: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-03 10:16:28.889871: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-01-03 10:16:29.047753: W external/local_xla/xla/stream_executor/gpu/redzone_allocator.cc:322] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2024-01-03 10:16:32.007742: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-03 10:16:32.260066: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-03 10:16:32.280810: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-03 10:16:32.308142: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-03 10:16:32.335340: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-03 10:16:32.371530: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-03 10:16:32.390040: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f0d606a0aa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-03 10:16:32.390055: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070, Compute Capability 8.9\n",
      "2024-01-03 10:16:32.397565: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1704273392.434839   16226 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3166/3166 [==============================] - 399s 122ms/step - d_loss: 0.6665 - g_loss: 1.1487\n",
      "Epoch 2/200\n",
      "3166/3166 [==============================] - 373s 118ms/step - d_loss: 0.7072 - g_loss: 0.7938\n",
      "Epoch 3/200\n",
      "3166/3166 [==============================] - 373s 118ms/step - d_loss: 0.7054 - g_loss: 0.7189\n",
      "Epoch 4/200\n",
      "3166/3166 [==============================] - 375s 118ms/step - d_loss: 0.6976 - g_loss: 0.7304\n",
      "Epoch 5/200\n",
      "3166/3166 [==============================] - 372s 117ms/step - d_loss: 0.6954 - g_loss: 0.7308\n",
      "Epoch 6/200\n",
      "3166/3166 [==============================] - 357s 113ms/step - d_loss: 0.6939 - g_loss: 0.7358\n",
      "Epoch 7/200\n",
      "3166/3166 [==============================] - 402s 127ms/step - d_loss: 0.6931 - g_loss: 0.7411\n",
      "Epoch 8/200\n",
      "3166/3166 [==============================] - 397s 125ms/step - d_loss: 0.6926 - g_loss: 0.7421\n",
      "Epoch 9/200\n",
      "3166/3166 [==============================] - 382s 121ms/step - d_loss: 0.6927 - g_loss: 0.7445\n",
      "Epoch 10/200\n",
      "3166/3166 [==============================] - 394s 125ms/step - d_loss: 0.6924 - g_loss: 0.7424\n",
      "Epoch 11/200\n",
      "3166/3166 [==============================] - 389s 123ms/step - d_loss: 0.6923 - g_loss: 0.7435\n",
      "Epoch 12/200\n",
      "3166/3166 [==============================] - 385s 122ms/step - d_loss: 0.6926 - g_loss: 0.7466\n",
      "Epoch 13/200\n",
      "3166/3166 [==============================] - 383s 121ms/step - d_loss: 0.6924 - g_loss: 0.7426\n",
      "Epoch 14/200\n",
      "3166/3166 [==============================] - 379s 120ms/step - d_loss: 0.6925 - g_loss: 0.7443\n",
      "Epoch 15/200\n",
      "3166/3166 [==============================] - 381s 120ms/step - d_loss: 0.6923 - g_loss: 0.7435\n",
      "Epoch 16/200\n",
      "3166/3166 [==============================] - 375s 119ms/step - d_loss: 0.6925 - g_loss: 0.7442\n",
      "Epoch 17/200\n",
      "3166/3166 [==============================] - 371s 117ms/step - d_loss: 0.6886 - g_loss: 0.7648\n",
      "Epoch 18/200\n",
      "3166/3166 [==============================] - 371s 117ms/step - d_loss: 0.6783 - g_loss: 0.8690\n",
      "Epoch 19/200\n",
      "3166/3166 [==============================] - 370s 117ms/step - d_loss: 0.6947 - g_loss: 0.7379\n",
      "Epoch 20/200\n",
      "3166/3166 [==============================] - 363s 115ms/step - d_loss: 0.6930 - g_loss: 0.7424\n",
      "Epoch 21/200\n",
      "3166/3166 [==============================] - 359s 113ms/step - d_loss: 0.6926 - g_loss: 0.7424\n",
      "Epoch 22/200\n",
      "3166/3166 [==============================] - 359s 113ms/step - d_loss: 0.6929 - g_loss: 0.7432\n",
      "Epoch 23/200\n",
      "3166/3166 [==============================] - 359s 113ms/step - d_loss: 0.6919 - g_loss: 0.7567\n",
      "Epoch 24/200\n",
      "3166/3166 [==============================] - 376s 119ms/step - d_loss: 0.6931 - g_loss: 0.7394\n",
      "Epoch 25/200\n",
      "3166/3166 [==============================] - 385s 122ms/step - d_loss: 0.6926 - g_loss: 0.7445\n",
      "Epoch 26/200\n",
      "3166/3166 [==============================] - 379s 120ms/step - d_loss: 0.6927 - g_loss: 0.7442\n",
      "Epoch 27/200\n",
      "3166/3166 [==============================] - 376s 119ms/step - d_loss: 0.6926 - g_loss: 0.7456\n",
      "Epoch 28/200\n",
      "3166/3166 [==============================] - 379s 120ms/step - d_loss: 0.6925 - g_loss: 0.7461\n",
      "Epoch 29/200\n",
      "3166/3166 [==============================] - 384s 121ms/step - d_loss: 0.6926 - g_loss: 0.7437\n",
      "Epoch 30/200\n",
      "3166/3166 [==============================] - 387s 122ms/step - d_loss: 0.6925 - g_loss: 0.7472\n",
      "Epoch 31/200\n",
      "3166/3166 [==============================] - 389s 123ms/step - d_loss: 0.6928 - g_loss: 0.7434\n",
      "Epoch 32/200\n",
      "3166/3166 [==============================] - 387s 122ms/step - d_loss: 0.6927 - g_loss: 0.7438\n",
      "Epoch 33/200\n",
      "3166/3166 [==============================] - 386s 122ms/step - d_loss: 0.6924 - g_loss: 0.7474\n",
      "Epoch 34/200\n",
      "3166/3166 [==============================] - 379s 120ms/step - d_loss: 0.6922 - g_loss: 0.7475\n",
      "Epoch 35/200\n",
      "3166/3166 [==============================] - 371s 117ms/step - d_loss: 0.6922 - g_loss: 0.7442\n",
      "Epoch 36/200\n",
      "3166/3166 [==============================] - 362s 114ms/step - d_loss: 0.6923 - g_loss: 0.7486\n",
      "Epoch 37/200\n",
      "3166/3166 [==============================] - 360s 114ms/step - d_loss: 0.6926 - g_loss: 0.7476\n",
      "Epoch 38/200\n",
      "3166/3166 [==============================] - 363s 115ms/step - d_loss: 0.6933 - g_loss: 0.7451\n",
      "Epoch 39/200\n",
      "3166/3166 [==============================] - 353s 112ms/step - d_loss: 0.6928 - g_loss: 0.7453\n",
      "Epoch 40/200\n",
      "3166/3166 [==============================] - 351s 111ms/step - d_loss: 0.6926 - g_loss: 0.7443\n",
      "Epoch 41/200\n",
      "3166/3166 [==============================] - 352s 111ms/step - d_loss: 0.6932 - g_loss: 0.7450\n",
      "Epoch 42/200\n",
      "3166/3166 [==============================] - 352s 111ms/step - d_loss: 0.6925 - g_loss: 0.7469\n",
      "Epoch 43/200\n",
      "3166/3166 [==============================] - 352s 111ms/step - d_loss: 0.6925 - g_loss: 0.7436\n",
      "Epoch 44/200\n",
      "3166/3166 [==============================] - 352s 111ms/step - d_loss: 0.6928 - g_loss: 0.7468\n",
      "Epoch 45/200\n",
      "3166/3166 [==============================] - 352s 111ms/step - d_loss: 0.6930 - g_loss: 0.7439\n",
      "Epoch 46/200\n",
      "3166/3166 [==============================] - 358s 113ms/step - d_loss: 0.6932 - g_loss: 0.7454\n",
      "Epoch 47/200\n",
      "3166/3166 [==============================] - 354s 112ms/step - d_loss: 0.6931 - g_loss: 0.7392\n",
      "Epoch 48/200\n",
      "3166/3166 [==============================] - 351s 111ms/step - d_loss: 0.6933 - g_loss: 0.7416\n",
      "Epoch 49/200\n",
      "3166/3166 [==============================] - 352s 111ms/step - d_loss: 0.6927 - g_loss: 0.7462\n",
      "Epoch 50/200\n",
      "3166/3166 [==============================] - 352s 111ms/step - d_loss: 0.6924 - g_loss: 0.7449\n",
      "Epoch 51/200\n",
      "3166/3166 [==============================] - 352s 111ms/step - d_loss: 0.6930 - g_loss: 0.7443\n",
      "Epoch 52/200\n",
      "3166/3166 [==============================] - 352s 111ms/step - d_loss: 0.6938 - g_loss: 0.7448\n",
      "Epoch 53/200\n",
      "3166/3166 [==============================] - 352s 111ms/step - d_loss: 0.6935 - g_loss: 0.7455\n",
      "Epoch 54/200\n",
      "3166/3166 [==============================] - 352s 111ms/step - d_loss: 0.6928 - g_loss: 0.7453\n",
      "Epoch 55/200\n",
      "3166/3166 [==============================] - 353s 111ms/step - d_loss: 0.6929 - g_loss: 0.7464\n",
      "Epoch 56/200\n",
      "3166/3166 [==============================] - 353s 111ms/step - d_loss: 0.6926 - g_loss: 0.7488\n",
      "Epoch 57/200\n",
      "3166/3166 [==============================] - 352s 111ms/step - d_loss: 0.6930 - g_loss: 0.7436\n",
      "Epoch 58/200\n",
      "3166/3166 [==============================] - 352s 111ms/step - d_loss: 0.6927 - g_loss: 0.7473\n",
      "Epoch 59/200\n",
      "3166/3166 [==============================] - 352s 111ms/step - d_loss: 0.6934 - g_loss: 0.7450\n",
      "Epoch 60/200\n",
      "3166/3166 [==============================] - 352s 111ms/step - d_loss: 0.6925 - g_loss: 0.7451\n",
      "Epoch 61/200\n",
      "3166/3166 [==============================] - 352s 111ms/step - d_loss: 0.6935 - g_loss: 0.7465\n",
      "Epoch 62/200\n",
      "3166/3166 [==============================] - 352s 111ms/step - d_loss: 0.6931 - g_loss: 0.7467\n",
      "Epoch 63/200\n",
      "3166/3166 [==============================] - 352s 111ms/step - d_loss: 0.6926 - g_loss: 0.7507\n",
      "Epoch 64/200\n",
      "3166/3166 [==============================] - 352s 111ms/step - d_loss: 0.6927 - g_loss: 0.7477\n",
      "Epoch 65/200\n",
      "3166/3166 [==============================] - 352s 111ms/step - d_loss: 0.6925 - g_loss: 0.7501\n",
      "Epoch 66/200\n",
      "3166/3166 [==============================] - 352s 111ms/step - d_loss: 0.6924 - g_loss: 0.7514\n",
      "Epoch 67/200\n",
      "3166/3166 [==============================] - 352s 111ms/step - d_loss: 0.6929 - g_loss: 0.7479\n",
      "Epoch 68/200\n",
      "3166/3166 [==============================] - 351s 111ms/step - d_loss: 0.6921 - g_loss: 0.7502\n",
      "Epoch 69/200\n",
      "3166/3166 [==============================] - 350s 111ms/step - d_loss: 0.6912 - g_loss: 0.7560\n",
      "Epoch 70/200\n",
      "3166/3166 [==============================] - 350s 110ms/step - d_loss: 0.6916 - g_loss: 0.7514\n",
      "Epoch 71/200\n",
      "3166/3166 [==============================] - 350s 111ms/step - d_loss: 0.6939 - g_loss: 0.7503\n",
      "Epoch 72/200\n",
      "3166/3166 [==============================] - 351s 111ms/step - d_loss: 0.6925 - g_loss: 0.7518\n",
      "Epoch 73/200\n",
      "3166/3166 [==============================] - 352s 111ms/step - d_loss: 0.6931 - g_loss: 0.7468\n",
      "Epoch 74/200\n",
      "3166/3166 [==============================] - 352s 111ms/step - d_loss: 0.6927 - g_loss: 0.7474\n",
      "Epoch 75/200\n",
      "3166/3166 [==============================] - 352s 111ms/step - d_loss: 0.6922 - g_loss: 0.7462\n",
      "Epoch 76/200\n",
      "3166/3166 [==============================] - 352s 111ms/step - d_loss: 0.6912 - g_loss: 0.7596\n",
      "Epoch 77/200\n",
      "3166/3166 [==============================] - 352s 111ms/step - d_loss: 0.6915 - g_loss: 0.7454\n",
      "Epoch 78/200\n",
      "3166/3166 [==============================] - 351s 111ms/step - d_loss: 0.6930 - g_loss: 0.7485\n",
      "Epoch 79/200\n",
      "3166/3166 [==============================] - 351s 111ms/step - d_loss: 0.6905 - g_loss: 0.7531\n",
      "Epoch 80/200\n",
      "3166/3166 [==============================] - 350s 111ms/step - d_loss: 0.6946 - g_loss: 0.7382\n",
      "Epoch 81/200\n",
      "3166/3166 [==============================] - 350s 111ms/step - d_loss: 0.6924 - g_loss: 0.7579\n",
      "Epoch 82/200\n",
      "3166/3166 [==============================] - 349s 110ms/step - d_loss: 0.6926 - g_loss: 0.7496\n",
      "Epoch 83/200\n",
      "3166/3166 [==============================] - 349s 110ms/step - d_loss: 0.6925 - g_loss: 0.7503\n",
      "Epoch 84/200\n",
      "3166/3166 [==============================] - 349s 110ms/step - d_loss: 0.6913 - g_loss: 0.7508\n",
      "Epoch 85/200\n",
      "3166/3166 [==============================] - 361s 114ms/step - d_loss: 0.6930 - g_loss: 0.7529\n",
      "Epoch 86/200\n",
      " 791/3166 [======>.......................] - ETA: 4:41 - d_loss: 0.6928 - g_loss: 0.7442"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mgan\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mGANMonitor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_img\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlatent_dim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlatent_dim\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1799\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1800\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1801\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1804\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1805\u001B[0m ):\n\u001B[1;32m   1806\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1807\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1808\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1809\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    829\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    831\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 832\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    834\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    835\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:877\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    874\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    875\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[1;32m    876\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[0;32m--> 877\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    878\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    880\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables:\n\u001B[1;32m    881\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    882\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1319\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1320\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1321\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1322\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1323\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1325\u001B[0m     args,\n\u001B[1;32m   1326\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1327\u001B[0m     executing_eagerly)\n\u001B[1;32m   1328\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    261\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1484\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1485\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1486\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1487\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1488\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1489\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1490\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1491\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1492\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1493\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1494\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1495\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1496\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1500\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1501\u001B[0m   )\n",
      "File \u001B[0;32m~/anaconda3/envs/tf/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "gan.fit(dataset, epochs=epochs, callbacks=[GANMonitor(num_img=1, latent_dim=latent_dim)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:53:29.875064006Z",
     "start_time": "2024-01-03T09:16:27.634711919Z"
    }
   },
   "id": "e78d7b9263b19505",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:53:29.876164846Z",
     "start_time": "2024-01-03T17:53:29.875568221Z"
    }
   },
   "id": "b228edba19f3751a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
