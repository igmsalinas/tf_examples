{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-28T16:30:02.356382320Z",
     "start_time": "2023-12-28T16:30:00.963427719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-12-28 17:30:01--  http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\r\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.201.91, 142.250.184.27, 142.250.185.27, ...\r\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.201.91|:80... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 2638744 (2.5M) [application/zip]\r\n",
      "Saving to: ‘spa-eng.zip’\r\n",
      "\r\n",
      "spa-eng.zip         100%[===================>]   2.52M  3.46MB/s    in 0.7s    \r\n",
      "\r\n",
      "2023-12-28 17:30:01 (3.46 MB/s) - ‘spa-eng.zip’ saved [2638744/2638744]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
    "!unzip -q spa-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "text_file = \"./spa-eng/spa.txt\"\n",
    "with open(text_file, \"r\") as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "text_pairs = []\n",
    "\n",
    "for line in lines:\n",
    "    english, spanish = line.split(\"\\t\")\n",
    "    spanish = \"[start] \" + spanish + \" [end]\"\n",
    "    text_pairs.append((english, spanish))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T16:32:37.918437066Z",
     "start_time": "2023-12-28T16:32:37.790807187Z"
    }
   },
   "id": "1b82407ac491f4f3",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"A painter's eyes are his most important tools.\", '[start] Los ojos de un pintor son sus herramientas más importantes. [end]')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print(random.choice(text_pairs))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T16:32:58.229528537Z",
     "start_time": "2023-12-28T16:32:58.224474218Z"
    }
   },
   "id": "f53500b8df7383ec",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "random.shuffle(text_pairs)\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "num_train_samples = len(text_pairs) - 2* num_val_samples\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
    "test_pairs = text_pairs[num_train_samples + num_val_samples:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T16:44:14.095185211Z",
     "start_time": "2023-12-28T16:44:14.053164804Z"
    }
   },
   "id": "234078c02da43fe6",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import string\n",
    "import re\n",
    "\n",
    "strip_chars = string.punctuation + \"¿\"\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(lowercase, f\"[{re.escape(strip_chars)}]\", \"\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T16:40:23.695826411Z",
     "start_time": "2023-12-28T16:40:23.691589284Z"
    }
   },
   "id": "4d312d36e1467441",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "vocab_size = 15000\n",
    "sequence_length = 20\n",
    "\n",
    "source_vectorization = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length\n",
    ")\n",
    "\n",
    "target_vectorization = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1,\n",
    "    standardize=custom_standardization,\n",
    ")\n",
    "\n",
    "train_english_texts = [pair[0] for pair in train_pairs]\n",
    "train_spanish_texts = [pair[1] for pair in train_pairs]\n",
    "source_vectorization.adapt(train_english_texts)\n",
    "target_vectorization.adapt(train_spanish_texts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T16:40:28.260723327Z",
     "start_time": "2023-12-28T16:40:24.507262070Z"
    }
   },
   "id": "f003266907e6abcb",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "def format_dataset(eng, spa):\n",
    "    eng = source_vectorization(eng)\n",
    "    spa = target_vectorization(spa)\n",
    "    return ({\n",
    "        \"english\": eng,\n",
    "        \"spanish\": spa[:, :-1]\n",
    "    }, spa[:, 1:])\n",
    "        \n",
    "def make_dataset(pairs):\n",
    "    eng_texts, spa_texts = zip(*pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    spa_texts = list(spa_texts)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
    "    return dataset.shuffle(2048).prefetch(buffer_size=16).cache()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T16:43:42.994693824Z",
     "start_time": "2023-12-28T16:43:42.993498496Z"
    }
   },
   "id": "9df0821013f8d958",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)\n",
    "test_ds = make_dataset(test_pairs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T16:44:23.243433606Z",
     "start_time": "2023-12-28T16:44:22.759252405Z"
    }
   },
   "id": "71983dd2721e021b",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 20)\n",
      "(64, 20)\n",
      "(64, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-28 17:45:31.221148: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = next(iter(train_ds))\n",
    "print(inputs['english'].shape)\n",
    "print(inputs['spanish'].shape)\n",
    "print(targets.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T16:45:31.224522430Z",
     "start_time": "2023-12-28T16:45:31.127654401Z"
    }
   },
   "id": "8bcd7b8822f25ca9",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-28 17:51:36.875995: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:225] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.9\n",
      "2023-12-28 17:51:36.876008: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:228] Used ptxas at ptxas\n",
      "2023-12-28 17:51:36.876050: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "embed_dim = 256\n",
    "latent_dim = 1024\n",
    "\n",
    "source = keras.Input(shape=(None,), dtype='int64', name='english')\n",
    "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(source)\n",
    "encoded_source = layers.Bidirectional(layers.GRU(latent_dim), merge_mode=\"sum\")(x)\n",
    "\n",
    "past_target = keras.Input(shape=(None,), dtype='int64', name='spanish')\n",
    "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(past_target)\n",
    "decoder_gru = layers.GRU(latent_dim, return_sequences=True)\n",
    "x = decoder_gru(x, initial_state=encoded_source)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "target_next_step = layers.Dense(vocab_size, activation='softmax')(x)\n",
    "seq2seq_rnn = keras.Model([source, past_target], target_next_step)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T16:51:38.746133128Z",
     "start_time": "2023-12-28T16:51:36.366723382Z"
    }
   },
   "id": "acca0b224230403a",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " english (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " spanish (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, None, 256)            3840000   ['english[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, None, 256)            3840000   ['spanish[0][0]']             \n",
      "                                                                                                  \n",
      " bidirectional (Bidirection  (None, 1024)                 7876608   ['embedding[0][0]']           \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " gru_1 (GRU)                 (None, None, 1024)           3938304   ['embedding_1[0][0]',         \n",
      "                                                                     'bidirectional[0][0]']       \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, None, 1024)           0         ['gru_1[0][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, None, 15000)          1537500   ['dropout[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 34869912 (133.02 MB)\n",
      "Trainable params: 34869912 (133.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq2seq_rnn.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "seq2seq_rnn.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T16:52:30.531416398Z",
     "start_time": "2023-12-28T16:52:30.460614623Z"
    }
   },
   "id": "3715800a4851d3bd",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-28 17:53:34.478277: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\tfor Tuple type infernce function 0\n",
      "\twhile inferring type of node 'cond_35/output/_22'\n",
      "2023-12-28 17:53:34.597636: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-12-28 17:53:34.657466: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-12-28 17:53:34.657482: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-12-28 17:53:34.657495: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-12-28 17:53:34.657504: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-12-28 17:53:34.658336: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-12-28 17:53:34.658504: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-12-28 17:53:34.658787: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-12-28 17:53:34.659272: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-12-28 17:53:34.736418: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-12-28 17:53:34.736435: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-12-28 17:53:34.736448: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-12-28 17:53:34.736644: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-12-28 17:53:34.736656: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-12-28 17:53:34.736956: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-12-28 17:53:34.737808: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-12-28 17:53:34.738456: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-12-28 17:53:34.794523: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2023-12-28 17:53:34.844964: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-12-28 17:53:34.845258: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-12-28 17:53:34.848169: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-12-28 17:53:34.848183: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-12-28 17:53:35.043033: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-12-28 17:53:35.044430: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-12-28 17:53:35.044447: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-12-28 17:53:35.044556: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-12-28 17:53:35.044887: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-12-28 17:53:35.045381: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-12-28 17:53:35.045524: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-12-28 17:53:35.046527: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-12-28 17:53:35.048259: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2023-12-28 17:53:35.311622: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f533e8f41c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-28 17:53:35.311638: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070, Compute Capability 8.9\n",
      "2023-12-28 17:53:35.318270: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1703782415.346297   54144 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1302/1302 [==============================] - 49s 33ms/step - loss: 4.6592 - accuracy: 0.3187 - val_loss: 3.9729 - val_accuracy: 0.3840\n",
      "Epoch 2/15\n",
      "1302/1302 [==============================] - 38s 29ms/step - loss: 3.7088 - accuracy: 0.4152 - val_loss: 3.3223 - val_accuracy: 0.4638\n",
      "Epoch 3/15\n",
      "1302/1302 [==============================] - 39s 30ms/step - loss: 3.2019 - accuracy: 0.4723 - val_loss: 2.9407 - val_accuracy: 0.5108\n",
      "Epoch 4/15\n",
      "1302/1302 [==============================] - 39s 30ms/step - loss: 2.8447 - accuracy: 0.5133 - val_loss: 2.6795 - val_accuracy: 0.5473\n",
      "Epoch 5/15\n",
      "1302/1302 [==============================] - 39s 30ms/step - loss: 2.5702 - accuracy: 0.5465 - val_loss: 2.5016 - val_accuracy: 0.5738\n",
      "Epoch 6/15\n",
      "1302/1302 [==============================] - 39s 30ms/step - loss: 2.3471 - accuracy: 0.5739 - val_loss: 2.3697 - val_accuracy: 0.5921\n",
      "Epoch 7/15\n",
      "1302/1302 [==============================] - 39s 30ms/step - loss: 2.1631 - accuracy: 0.5979 - val_loss: 2.2782 - val_accuracy: 0.6060\n",
      "Epoch 8/15\n",
      "1302/1302 [==============================] - 40s 30ms/step - loss: 2.0078 - accuracy: 0.6192 - val_loss: 2.1994 - val_accuracy: 0.6199\n",
      "Epoch 9/15\n",
      "1302/1302 [==============================] - 38s 29ms/step - loss: 1.8730 - accuracy: 0.6374 - val_loss: 2.1487 - val_accuracy: 0.6273\n",
      "Epoch 10/15\n",
      "1302/1302 [==============================] - 39s 30ms/step - loss: 1.7524 - accuracy: 0.6543 - val_loss: 2.1036 - val_accuracy: 0.6333\n",
      "Epoch 11/15\n",
      "1302/1302 [==============================] - 39s 30ms/step - loss: 1.6472 - accuracy: 0.6694 - val_loss: 2.0620 - val_accuracy: 0.6411\n",
      "Epoch 12/15\n",
      "1302/1302 [==============================] - 39s 30ms/step - loss: 1.5557 - accuracy: 0.6824 - val_loss: 2.0383 - val_accuracy: 0.6445\n",
      "Epoch 13/15\n",
      "1302/1302 [==============================] - 39s 30ms/step - loss: 1.4765 - accuracy: 0.6936 - val_loss: 2.0157 - val_accuracy: 0.6498\n",
      "Epoch 14/15\n",
      "1302/1302 [==============================] - 39s 30ms/step - loss: 1.4034 - accuracy: 0.7043 - val_loss: 2.0031 - val_accuracy: 0.6514\n",
      "Epoch 15/15\n",
      "1302/1302 [==============================] - 39s 30ms/step - loss: 1.3430 - accuracy: 0.7138 - val_loss: 1.9853 - val_accuracy: 0.6547\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x7f53bc60b210>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint('seq2seq_rnn.keras', save_best_only=True)]\n",
    "seq2seq_rnn.fit(train_ds, epochs=15, validation_data=val_ds, callbacks=callbacks)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T17:03:24.915143264Z",
     "start_time": "2023-12-28T16:53:30.074575525Z"
    }
   },
   "id": "18b1395938067008",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Tom planted some flower seeds in his garden.\n",
      "[start] tom plantó un poco de [UNK] en su jardín [end]\n",
      "-\n",
      "There are many words with meanings I don't know.\n",
      "[start] hay muchas palabras con no lo que sé [end]\n",
      "-\n",
      "My father has never gotten sick in his life.\n",
      "[start] mi padre nunca ha estado en su vida [end]\n",
      "-\n",
      "Has Tom gone insane?\n",
      "[start] ha tom se ha vuelto loco [end]\n",
      "-\n",
      "Tom jumped off a cliff.\n",
      "[start] tom [UNK] un [UNK] [end]\n",
      "-\n",
      "It's even very cold in May.\n",
      "[start] está muy cansado así ahora [end]\n",
      "-\n",
      "We heard her cry.\n",
      "[start] oímos a su hijo [end]\n",
      "-\n",
      "The doctor advised him not to smoke.\n",
      "[start] el doctor le aconsejó que no se [UNK] [end]\n",
      "-\n",
      "He can't have said such a stupid thing.\n",
      "[start] Él no puede haber dicho una cosa muy [end]\n",
      "-\n",
      "This is a real breakthrough.\n",
      "[start] esto es un [UNK] [end]\n",
      "-\n",
      "I'm here to help.\n",
      "[start] estoy aquí para ayudar [end]\n",
      "-\n",
      "That was the idea.\n",
      "[start] ese era la idea [end]\n",
      "-\n",
      "Isn't that a little harsh?\n",
      "[start] no es un poco de [UNK] [end]\n",
      "-\n",
      "She wants to play golf with him.\n",
      "[start] ella quiere jugar al golf con él [end]\n",
      "-\n",
      "We're worried about Grandma and Grandpa.\n",
      "[start] estamos preocupados por la [UNK] y [UNK] [end]\n",
      "-\n",
      "Are you certain about this?\n",
      "[start] estás seguro de esto [end]\n",
      "-\n",
      "Who broke this?\n",
      "[start] quién se rompió este [end]\n",
      "-\n",
      "There's no one named Tom here.\n",
      "[start] aquí no hay nadie aquí [end]\n",
      "-\n",
      "Tom should've danced with Mary.\n",
      "[start] tom debió haber quedado con mary [end]\n",
      "-\n",
      "Please don't open the window.\n",
      "[start] no favor abra la ventana por favor [end]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "spa_vocab = target_vectorization.get_vocabulary()\n",
    "spa_index_lookop = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "def decode_sequence(input_sequence):\n",
    "    tokenized_input_sequence = source_vectorization([input_sequence])\n",
    "    decoded_sequence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sequence = target_vectorization([decoded_sequence])\n",
    "        next_token_prediction = seq2seq_rnn.predict([tokenized_input_sequence, tokenized_target_sequence], verbose=0)\n",
    "        sampled_token_index = np.argmax(next_token_prediction[0, i, :])\n",
    "        sampled_token = spa_index_lookop[sampled_token_index]\n",
    "        decoded_sequence += \" \" + sampled_token\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sequence\n",
    "\n",
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "for _ in range(max_decoded_sentence_length):\n",
    "    input_sentence = random.choice(test_eng_texts)\n",
    "    print(\"-\")\n",
    "    print(input_sentence)\n",
    "    print(decode_sequence(input_sentence))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T18:36:32.500680797Z",
     "start_time": "2023-12-28T18:36:27.907309829Z"
    }
   },
   "id": "3ace5d8215a8ae18",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embedding = layers.Embedding(input_dim=input_dim, output_dim=output_dim)\n",
    "        self.position_embedding = layers.Embedding(input_dim=sequence_length, output_dim=output_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embedding(inputs)\n",
    "        embedded_positions = self.position_embedding(positions)\n",
    "        embedding = embedded_tokens + embedded_positions\n",
    "        return embedding\n",
    "    \n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"input_dim\": self.input_dim\n",
    "        })\n",
    "        return config"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T18:41:06.475027029Z",
     "start_time": "2023-12-28T18:41:06.433302704Z"
    }
   },
   "id": "b3a6bc63a0156bc4",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dense_dim = dense_dim\n",
    "        self.attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_projection = keras.Sequential([layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim)])\n",
    "        self.layer_norm1 = layers.LayerNormalization()\n",
    "        self.layer_norm2 = layers.LayerNormalization()\n",
    "        \n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :]\n",
    "        attention_output = self.attention(inputs, inputs, attention_mask=mask)\n",
    "        projection_input = self.layer_norm1(inputs + attention_output) \n",
    "        projection_output = self.dense_projection(projection_input)\n",
    "        return self.layer_norm2(projection_output + projection_input)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'embed_dim': self.embed_dim,\n",
    "            'num_heads': self.num_heads,\n",
    "            'dense_dim': self.dense_dim,\n",
    "        })\n",
    "        return config"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T18:41:06.991560690Z",
     "start_time": "2023-12-28T18:41:06.989875540Z"
    }
   },
   "id": "40068afc456746f6",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention1 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.attention2 = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_projection = keras.Sequential([layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim)])\n",
    "        self.layer_norm1 = layers.LayerNormalization()\n",
    "        self.layer_norm2 = layers.LayerNormalization()\n",
    "        self.layer_norm3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'embed_dim': self.embed_dim,\n",
    "            'dense_dim': self.dense_dim,\n",
    "            'num_heads': self.num_heads\n",
    "        })\n",
    "        return config\n",
    "    \n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, seq_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(seq_length)[:, tf.newaxis]\n",
    "        j = tf.range(seq_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat([tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=\"int32\")], axis=0)\n",
    "        return tf.tile(mask, mult)\n",
    "    \n",
    "    def call(self, inputs, enconder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "        attention_output_1 = self.attention1(\n",
    "            query=inputs,\n",
    "            value=inputs,\n",
    "            key=inputs,\n",
    "            attention_mask=causal_mask \n",
    "        )\n",
    "        attention_output_1 = self.layer_norm1(inputs + attention_output_1)\n",
    "        attention_output_2 = self.attention2(\n",
    "            query=attention_output_1, value=enconder_outputs, key=enconder_outputs, attention_mask=padding_mask\n",
    "        )\n",
    "        attention_output_2 = self.layer_norm2(attention_output_1 + attention_output_2)\n",
    "        projection_output = self.dense_projection(attention_output_2)\n",
    "        return self.layer_norm3(projection_output + attention_output_2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T19:00:21.855671816Z",
     "start_time": "2023-12-28T19:00:21.792740376Z"
    }
   },
   "id": "f53ccdbd501f8efe",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "num_heads = 8\n",
    "dense_dim = 2048\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(None, ), dtype=\"int64\", name=\"english\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
    "encoder_outputs =TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None, ), dtype=\"int64\", name=\"spanish\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "transformer = keras.Model(inputs=[encoder_inputs, decoder_inputs], outputs=[decoder_outputs])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T19:00:58.826260015Z",
     "start_time": "2023-12-28T19:00:58.568119933Z"
    }
   },
   "id": "6bdf82a2ae062853",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "transformer.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T19:01:25.024271947Z",
     "start_time": "2023-12-28T19:01:24.967067339Z"
    }
   },
   "id": "20f1683ae3edf48c",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " english (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " spanish (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " positional_embedding_4 (Po  (None, None, 256)            3845120   ['english[0][0]']             \n",
      " sitionalEmbedding)                                                                               \n",
      "                                                                                                  \n",
      " positional_embedding_5 (Po  (None, None, 256)            3845120   ['spanish[0][0]']             \n",
      " sitionalEmbedding)                                                                               \n",
      "                                                                                                  \n",
      " transformer_encoder_2 (Tra  (None, None, 256)            3155456   ['positional_embedding_4[0][0]\n",
      " nsformerEncoder)                                                   ']                            \n",
      "                                                                                                  \n",
      " transformer_decoder_2 (Tra  (None, None, 256)            5259520   ['positional_embedding_5[0][0]\n",
      " nsformerDecoder)                                                   ',                            \n",
      "                                                                     'transformer_encoder_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, None, 256)            0         ['transformer_decoder_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, None, 15000)          3855000   ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 19960216 (76.14 MB)\n",
      "Trainable params: 19960216 (76.14 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T19:01:28.680507115Z",
     "start_time": "2023-12-28T19:01:28.637078367Z"
    }
   },
   "id": "60ddb9ed23218a38",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-28 20:01:42.698098: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1302/1302 [==============================] - 42s 30ms/step - loss: 3.7635 - accuracy: 0.4424 - val_loss: 2.9228 - val_accuracy: 0.5345\n",
      "Epoch 2/30\n",
      "1302/1302 [==============================] - 33s 25ms/step - loss: 2.8231 - accuracy: 0.5515 - val_loss: 2.5540 - val_accuracy: 0.5876\n",
      "Epoch 3/30\n",
      "1302/1302 [==============================] - 33s 25ms/step - loss: 2.5304 - accuracy: 0.5947 - val_loss: 2.4129 - val_accuracy: 0.6127\n",
      "Epoch 4/30\n",
      "1302/1302 [==============================] - 33s 25ms/step - loss: 2.3689 - accuracy: 0.6212 - val_loss: 2.3804 - val_accuracy: 0.6220\n",
      "Epoch 5/30\n",
      "1302/1302 [==============================] - 33s 25ms/step - loss: 2.2637 - accuracy: 0.6394 - val_loss: 2.3372 - val_accuracy: 0.6334\n",
      "Epoch 6/30\n",
      "1302/1302 [==============================] - 33s 25ms/step - loss: 2.1899 - accuracy: 0.6530 - val_loss: 2.3414 - val_accuracy: 0.6349\n",
      "Epoch 7/30\n",
      "1302/1302 [==============================] - 33s 25ms/step - loss: 2.1319 - accuracy: 0.6643 - val_loss: 2.3244 - val_accuracy: 0.6409\n",
      "Epoch 8/30\n",
      "1302/1302 [==============================] - 33s 25ms/step - loss: 2.0680 - accuracy: 0.6769 - val_loss: 2.2872 - val_accuracy: 0.6501\n",
      "Epoch 9/30\n",
      "1302/1302 [==============================] - 35s 27ms/step - loss: 2.0101 - accuracy: 0.6877 - val_loss: 2.2829 - val_accuracy: 0.6541\n",
      "Epoch 10/30\n",
      "1302/1302 [==============================] - 34s 26ms/step - loss: 1.9621 - accuracy: 0.6965 - val_loss: 2.2733 - val_accuracy: 0.6576\n",
      "Epoch 11/30\n",
      "1302/1302 [==============================] - 32s 25ms/step - loss: 1.9237 - accuracy: 0.7034 - val_loss: 2.2749 - val_accuracy: 0.6590\n",
      "Epoch 12/30\n",
      "1302/1302 [==============================] - 33s 25ms/step - loss: 1.8902 - accuracy: 0.7094 - val_loss: 2.2786 - val_accuracy: 0.6611\n",
      "Epoch 13/30\n",
      "1302/1302 [==============================] - 33s 26ms/step - loss: 1.8629 - accuracy: 0.7142 - val_loss: 2.2940 - val_accuracy: 0.6616\n",
      "Epoch 14/30\n",
      "1302/1302 [==============================] - 34s 26ms/step - loss: 1.8391 - accuracy: 0.7190 - val_loss: 2.2984 - val_accuracy: 0.6614\n",
      "Epoch 15/30\n",
      "1302/1302 [==============================] - 32s 25ms/step - loss: 1.8176 - accuracy: 0.7227 - val_loss: 2.3042 - val_accuracy: 0.6635\n",
      "Epoch 16/30\n",
      "1302/1302 [==============================] - 32s 25ms/step - loss: 1.7979 - accuracy: 0.7267 - val_loss: 2.3353 - val_accuracy: 0.6610\n",
      "Epoch 17/30\n",
      "1302/1302 [==============================] - 32s 25ms/step - loss: 1.7801 - accuracy: 0.7298 - val_loss: 2.3324 - val_accuracy: 0.6668\n",
      "Epoch 18/30\n",
      "1302/1302 [==============================] - 32s 24ms/step - loss: 1.7626 - accuracy: 0.7330 - val_loss: 2.3752 - val_accuracy: 0.6636\n",
      "Epoch 19/30\n",
      "1302/1302 [==============================] - 32s 25ms/step - loss: 1.7476 - accuracy: 0.7355 - val_loss: 2.3447 - val_accuracy: 0.6682\n",
      "Epoch 20/30\n",
      "1302/1302 [==============================] - 32s 25ms/step - loss: 1.7347 - accuracy: 0.7385 - val_loss: 2.3648 - val_accuracy: 0.6658\n",
      "Epoch 21/30\n",
      "1302/1302 [==============================] - 32s 25ms/step - loss: 1.7191 - accuracy: 0.7411 - val_loss: 2.3530 - val_accuracy: 0.6686\n",
      "Epoch 22/30\n",
      "1302/1302 [==============================] - 32s 25ms/step - loss: 1.7028 - accuracy: 0.7444 - val_loss: 2.3999 - val_accuracy: 0.6672\n",
      "Epoch 23/30\n",
      "1302/1302 [==============================] - 32s 25ms/step - loss: 1.6917 - accuracy: 0.7462 - val_loss: 2.4211 - val_accuracy: 0.6661\n",
      "Epoch 24/30\n",
      "1302/1302 [==============================] - 32s 25ms/step - loss: 1.6775 - accuracy: 0.7485 - val_loss: 2.4158 - val_accuracy: 0.6681\n",
      "Epoch 25/30\n",
      "1302/1302 [==============================] - 32s 25ms/step - loss: 1.6626 - accuracy: 0.7517 - val_loss: 2.4169 - val_accuracy: 0.6684\n",
      "Epoch 26/30\n",
      "1302/1302 [==============================] - 32s 25ms/step - loss: 1.6502 - accuracy: 0.7539 - val_loss: 2.4179 - val_accuracy: 0.6693\n",
      "Epoch 27/30\n",
      "1302/1302 [==============================] - 32s 25ms/step - loss: 1.6369 - accuracy: 0.7561 - val_loss: 2.4491 - val_accuracy: 0.6678\n",
      "Epoch 28/30\n",
      "1302/1302 [==============================] - 33s 25ms/step - loss: 1.6224 - accuracy: 0.7591 - val_loss: 2.4502 - val_accuracy: 0.6716\n",
      "Epoch 29/30\n",
      "1302/1302 [==============================] - 32s 25ms/step - loss: 1.6128 - accuracy: 0.7604 - val_loss: 2.4906 - val_accuracy: 0.6615\n",
      "Epoch 30/30\n",
      "1302/1302 [==============================] - 32s 25ms/step - loss: 1.5967 - accuracy: 0.7631 - val_loss: 2.4952 - val_accuracy: 0.6651\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x7f5331962fd0>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.fit(train_ds, validation_data=val_ds, epochs=30)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T19:18:08.185800616Z",
     "start_time": "2023-12-28T19:01:40.797417628Z"
    }
   },
   "id": "6dca1efac3ebc578",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "I went to the park yesterday.\n",
      "[start] ayer fui al parque [end]\n",
      "-\n",
      "I've never been more proud of you.\n",
      "[start] nunca he estado más orgulloso de ti [end]\n",
      "-\n",
      "You'll understand it right away.\n",
      "[start] lo [UNK] de verdad [end]\n",
      "-\n",
      "Get your mind out of the gutter!\n",
      "[start] [UNK] de la cabeza [end]\n",
      "-\n",
      "I need to go somewhere and think.\n",
      "[start] necesito ir a lugar en alguna parte [end]\n",
      "-\n",
      "There is an apple on the table.\n",
      "[start] hay una manzana sobre la mesa [end]\n",
      "-\n",
      "I have some presents for you.\n",
      "[start] tengo libros para comprar ustedes [end]\n",
      "-\n",
      "He didn't get caught.\n",
      "[start] Él no levantó [end]\n",
      "-\n",
      "It's raining very hard.\n",
      "[start] está lloviendo muy difícil [end]\n",
      "-\n",
      "I don't know her and I don't think I want to.\n",
      "[start] no sé que no y yo no quiero pensar [end]\n",
      "-\n",
      "That sounds scary.\n",
      "[start] eso me parece la miedo [end]\n",
      "-\n",
      "You are not old enough to go swimming by yourself.\n",
      "[start] tú no eres lo suficientemente mayor para ir a menudo [end]\n",
      "-\n",
      "He failed to catch the 8:30 train.\n",
      "[start] hizo [UNK] para el tren de las [UNK] [end]\n",
      "-\n",
      "I only spent three dollars.\n",
      "[start] solo compré tres dólares [end]\n",
      "-\n",
      "Tom never makes the same mistake twice.\n",
      "[start] tom nunca [UNK] el mismo error dos veces [end]\n",
      "-\n",
      "I just want to improve as much as I can.\n",
      "[start] solo quiero distinguir a [UNK] [end]\n",
      "-\n",
      "That room is not very large.\n",
      "[start] la habitación no es muy grande [end]\n",
      "-\n",
      "Close your eyes and take a deep breath.\n",
      "[start] cierra los ojos y [UNK] un [UNK] [end]\n",
      "-\n",
      "Why didn't you go to school today?\n",
      "[start] por qué no vayas a la escuela hoy [end]\n",
      "-\n",
      "Tom attempted to predict the results.\n",
      "[start] tom intentó [UNK] los resultados [end]\n"
     ]
    }
   ],
   "source": [
    "spa_vocab = target_vectorization.get_vocabulary()\n",
    "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "def decode_sequence(input_sequence):\n",
    "    tokenized_input_sequence = source_vectorization([input_sequence])\n",
    "    decoded_sequence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sequence = target_vectorization([decoded_sequence])[:, :-1]\n",
    "        next_token_prediction = transformer.predict([tokenized_input_sequence, tokenized_target_sequence], verbose=0)\n",
    "        sampled_token_index = np.argmax(next_token_prediction[0, i, :])\n",
    "        sampled_token = spa_index_lookop[sampled_token_index]\n",
    "        decoded_sequence += \" \" + sampled_token\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sequence\n",
    "\n",
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "for _ in range(20):\n",
    "    input_sentence = random.choice(test_eng_texts)\n",
    "    print(\"-\")\n",
    "    print(input_sentence)\n",
    "    print(decode_sequence(input_sentence))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T19:21:14.252188506Z",
     "start_time": "2023-12-28T19:21:09.621699551Z"
    }
   },
   "id": "18d44ba224a4e91b",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "num_heads = 8\n",
    "dense_dim = 2048\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(None, ), dtype=\"int64\", name=\"english\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
    "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None, ), dtype=\"int64\", name=\"spanish\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
    "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "transformer = keras.Model(inputs=[encoder_inputs, decoder_inputs], outputs=[decoder_outputs])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T19:32:12.770096129Z",
     "start_time": "2023-12-28T19:32:11.861388421Z"
    }
   },
   "id": "be0a8ae4c63893dc",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " english (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " positional_embedding_10 (P  (None, None, 256)            3845120   ['english[0][0]']             \n",
      " ositionalEmbedding)                                                                              \n",
      "                                                                                                  \n",
      " transformer_encoder_13 (Tr  (None, None, 256)            3155456   ['positional_embedding_10[0][0\n",
      " ansformerEncoder)                                                  ]']                           \n",
      "                                                                                                  \n",
      " spanish (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " transformer_encoder_14 (Tr  (None, None, 256)            3155456   ['transformer_encoder_13[0][0]\n",
      " ansformerEncoder)                                                  ']                            \n",
      "                                                                                                  \n",
      " positional_embedding_11 (P  (None, None, 256)            3845120   ['spanish[0][0]']             \n",
      " ositionalEmbedding)                                                                              \n",
      "                                                                                                  \n",
      " transformer_encoder_15 (Tr  (None, None, 256)            3155456   ['transformer_encoder_14[0][0]\n",
      " ansformerEncoder)                                                  ']                            \n",
      "                                                                                                  \n",
      " transformer_decoder_12 (Tr  (None, None, 256)            5259520   ['positional_embedding_11[0][0\n",
      " ansformerDecoder)                                                  ]',                           \n",
      "                                                                     'transformer_encoder_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " transformer_decoder_13 (Tr  (None, None, 256)            5259520   ['transformer_decoder_12[0][0]\n",
      " ansformerDecoder)                                                  ',                            \n",
      "                                                                     'transformer_encoder_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, None, 256)            0         ['transformer_decoder_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_64 (Dense)            (None, None, 15000)          3855000   ['dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31530648 (120.28 MB)\n",
      "Trainable params: 31530648 (120.28 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T19:32:13.711493249Z",
     "start_time": "2023-12-28T19:32:13.662566528Z"
    }
   },
   "id": "5d27b305ec19800e",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "transformer.compile(optimizer='rmsprop', loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T19:32:22.932907435Z",
     "start_time": "2023-12-28T19:32:22.915520650Z"
    }
   },
   "id": "2d1007c13a80f22a",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1302/1302 [==============================] - 62s 44ms/step - loss: 4.0711 - accuracy: 0.4010 - val_loss: 3.1254 - val_accuracy: 0.5091\n",
      "Epoch 2/30\n",
      "1302/1302 [==============================] - 54s 42ms/step - loss: 2.9774 - accuracy: 0.5317 - val_loss: 2.6505 - val_accuracy: 0.5742\n",
      "Epoch 3/30\n",
      "1302/1302 [==============================] - 53s 41ms/step - loss: 2.6002 - accuracy: 0.5869 - val_loss: 2.4568 - val_accuracy: 0.6092\n",
      "Epoch 4/30\n",
      "1302/1302 [==============================] - 55s 42ms/step - loss: 2.3464 - accuracy: 0.6284 - val_loss: 2.2739 - val_accuracy: 0.6417\n",
      "Epoch 5/30\n",
      "1302/1302 [==============================] - 54s 42ms/step - loss: 2.1788 - accuracy: 0.6555 - val_loss: 2.1925 - val_accuracy: 0.6565\n",
      "Epoch 6/30\n",
      "1302/1302 [==============================] - 56s 43ms/step - loss: 2.0684 - accuracy: 0.6743 - val_loss: 2.1510 - val_accuracy: 0.6686\n",
      "Epoch 7/30\n",
      "1302/1302 [==============================] - 56s 43ms/step - loss: 1.9975 - accuracy: 0.6871 - val_loss: 2.1788 - val_accuracy: 0.6682\n",
      "Epoch 8/30\n",
      "1302/1302 [==============================] - 54s 41ms/step - loss: 1.9451 - accuracy: 0.6969 - val_loss: 2.1548 - val_accuracy: 0.6678\n",
      "Epoch 9/30\n",
      "1302/1302 [==============================] - 55s 42ms/step - loss: 1.9049 - accuracy: 0.7043 - val_loss: 2.1730 - val_accuracy: 0.6740\n",
      "Epoch 10/30\n",
      "1302/1302 [==============================] - 57s 44ms/step - loss: 1.8721 - accuracy: 0.7109 - val_loss: 2.1935 - val_accuracy: 0.6738\n",
      "Epoch 11/30\n",
      "1302/1302 [==============================] - 56s 43ms/step - loss: 1.8437 - accuracy: 0.7162 - val_loss: 2.1871 - val_accuracy: 0.6780\n",
      "Epoch 12/30\n",
      "1302/1302 [==============================] - 53s 41ms/step - loss: 1.8180 - accuracy: 0.7212 - val_loss: 2.2172 - val_accuracy: 0.6767\n",
      "Epoch 13/30\n",
      "1302/1302 [==============================] - 52s 40ms/step - loss: 1.7950 - accuracy: 0.7255 - val_loss: 2.2038 - val_accuracy: 0.6803\n",
      "Epoch 14/30\n",
      "1302/1302 [==============================] - 52s 40ms/step - loss: 1.7761 - accuracy: 0.7290 - val_loss: 2.2050 - val_accuracy: 0.6800\n",
      "Epoch 15/30\n",
      "1302/1302 [==============================] - 52s 40ms/step - loss: 1.7564 - accuracy: 0.7328 - val_loss: 2.2159 - val_accuracy: 0.6821\n",
      "Epoch 16/30\n",
      "1302/1302 [==============================] - 52s 40ms/step - loss: 1.7343 - accuracy: 0.7368 - val_loss: 2.2285 - val_accuracy: 0.6819\n",
      "Epoch 17/30\n",
      "1302/1302 [==============================] - 52s 40ms/step - loss: 1.7200 - accuracy: 0.7398 - val_loss: 2.2411 - val_accuracy: 0.6781\n",
      "Epoch 18/30\n",
      "1302/1302 [==============================] - 52s 40ms/step - loss: 1.7019 - accuracy: 0.7431 - val_loss: 2.2574 - val_accuracy: 0.6798\n",
      "Epoch 19/30\n",
      "1302/1302 [==============================] - 52s 40ms/step - loss: 1.6853 - accuracy: 0.7462 - val_loss: 2.2658 - val_accuracy: 0.6816\n",
      "Epoch 20/30\n",
      "1302/1302 [==============================] - 52s 40ms/step - loss: 1.6724 - accuracy: 0.7488 - val_loss: 2.2975 - val_accuracy: 0.6786\n",
      "Epoch 21/30\n",
      "1302/1302 [==============================] - 52s 40ms/step - loss: 1.6567 - accuracy: 0.7514 - val_loss: 2.2665 - val_accuracy: 0.6846\n",
      "Epoch 22/30\n",
      "1302/1302 [==============================] - 52s 40ms/step - loss: 1.6413 - accuracy: 0.7540 - val_loss: 2.3012 - val_accuracy: 0.6809\n",
      "Epoch 23/30\n",
      "1302/1302 [==============================] - 52s 40ms/step - loss: 1.6327 - accuracy: 0.7554 - val_loss: 2.3027 - val_accuracy: 0.6824\n",
      "Epoch 24/30\n",
      "1302/1302 [==============================] - 52s 40ms/step - loss: 1.6180 - accuracy: 0.7583 - val_loss: 2.2847 - val_accuracy: 0.6843\n",
      "Epoch 25/30\n",
      "1302/1302 [==============================] - 53s 40ms/step - loss: 1.6056 - accuracy: 0.7606 - val_loss: 2.2890 - val_accuracy: 0.6870\n",
      "Epoch 26/30\n",
      "1302/1302 [==============================] - 53s 41ms/step - loss: 1.5920 - accuracy: 0.7630 - val_loss: 2.3347 - val_accuracy: 0.6797\n",
      "Epoch 27/30\n",
      "1302/1302 [==============================] - 53s 40ms/step - loss: 1.5812 - accuracy: 0.7648 - val_loss: 2.3621 - val_accuracy: 0.6851\n",
      "Epoch 28/30\n",
      "1302/1302 [==============================] - 52s 40ms/step - loss: 1.5692 - accuracy: 0.7671 - val_loss: 2.3026 - val_accuracy: 0.6850\n",
      "Epoch 29/30\n",
      "1302/1302 [==============================] - 53s 41ms/step - loss: 1.5562 - accuracy: 0.7691 - val_loss: 2.3590 - val_accuracy: 0.6821\n",
      "Epoch 30/30\n",
      "1302/1302 [==============================] - 53s 40ms/step - loss: 1.5452 - accuracy: 0.7707 - val_loss: 2.3521 - val_accuracy: 0.6833\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.src.callbacks.History at 0x7f50541f7890>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.fit(train_ds, validation_data=val_ds, epochs=30)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T19:59:09.774285814Z",
     "start_time": "2023-12-28T19:32:24.258937783Z"
    }
   },
   "id": "5e2a0cd976b2a2a8",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "That boy is intelligent.\n",
      "[start] ese chico es inteligente [end]\n",
      "-\n",
      "I'd like to hear you talk more about that.\n",
      "[start] me gustaría oír algo más [end]\n",
      "-\n",
      "Are you Tom's brother?\n",
      "[start] es usted el hermano de tom [end]\n",
      "-\n",
      "She is beautiful.\n",
      "[start] es guapa [end]\n",
      "-\n",
      "What happened to you two?\n",
      "[start] qué te pasó a ti dos [end]\n",
      "-\n",
      "Tom should be jailed.\n",
      "[start] tom debería ser [UNK] [end]\n",
      "-\n",
      "The police are looking for suspects.\n",
      "[start] la policía está buscando a los [UNK] [end]\n",
      "-\n",
      "I find myself in a rather delicate situation.\n",
      "[start] yo encontré un [UNK] en una situación eso [end]\n",
      "-\n",
      "What's so strange about that?\n",
      "[start] qué es tan extraño [end]\n",
      "-\n",
      "We're having a meeting at 2:30.\n",
      "[start] estamos tener una reunión a las dos y media [end]\n",
      "-\n",
      "Can I call my friend in Japan?\n",
      "[start] puede llamar a mi amigo en japón [end]\n",
      "-\n",
      "It can happen to anybody.\n",
      "[start] le puede pasar a cualquiera [end]\n",
      "-\n",
      "Leaving the children alone was sheer thoughtlessness.\n",
      "[start] dejar a los niños solo [UNK] [UNK] [end]\n",
      "-\n",
      "My father has five siblings.\n",
      "[start] mi padre tiene cinco hermanos [end]\n",
      "-\n",
      "Are you interested in Buddhism?\n",
      "[start] te importa lo [UNK] [end]\n",
      "-\n",
      "They were ready for action.\n",
      "[start] estaban listos para que [UNK] [end]\n",
      "-\n",
      "We're running late.\n",
      "[start] vamos con [UNK] [end]\n",
      "-\n",
      "Tom spent the night in jail.\n",
      "[start] tom pasó la noche en la cárcel [end]\n",
      "-\n",
      "This air conditioner consumes a lot of electricity.\n",
      "[start] este aire yenes las [UNK] mucha que la [UNK] [end]\n",
      "-\n",
      "May I go with him?\n",
      "[start] puedo ir con él [end]\n"
     ]
    }
   ],
   "source": [
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "for _ in range(20):\n",
    "    input_sentence = random.choice(test_eng_texts)\n",
    "    print(\"-\")\n",
    "    print(input_sentence)\n",
    "    print(decode_sequence(input_sentence))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T20:05:34.874469859Z",
     "start_time": "2023-12-28T20:05:29.595611684Z"
    }
   },
   "id": "b0ad821b33e0d64b",
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a4fcf8dd2c5fdd9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
